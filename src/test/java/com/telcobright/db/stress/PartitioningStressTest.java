package com.telcobright.db.stress;

import com.telcobright.db.connection.ConnectionProvider;
import com.telcobright.db.metadata.EntityMetadata;
import com.telcobright.db.test.entity.TestEntity;
import org.junit.jupiter.api.*;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.testcontainers.containers.MySQLContainer;
import org.testcontainers.junit.jupiter.Container;
import org.testcontainers.junit.jupiter.Testcontainers;

import java.math.BigDecimal;
import java.sql.*;
import java.time.LocalDateTime;
import java.time.format.DateTimeFormatter;
import java.time.temporal.ChronoUnit;
import java.util.*;
import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;

import static org.assertj.core.api.Assertions.*;

/**
 * COMPREHENSIVE PARTITIONING STRESS TEST
 * 
 * Tests rock-solid reliability of:
 * - Automatic partitioning with daily tables + hourly partitions
 * - Million+ record insertions across multiple days/hours
 * - Partition indexing and pruning
 * - Corner cases: timezone boundaries, leap years, month boundaries
 * - Concurrent access scenarios
 * - Memory and performance under extreme load
 */
@Testcontainers
@DisplayName("üî• PARTITIONING STRESS TEST - Million Iterations")
@TestMethodOrder(MethodOrderer.OrderAnnotation.class)
public class PartitioningStressTest {
    
    private static final Logger logger = LoggerFactory.getLogger(PartitioningStressTest.class);
    private static final DateTimeFormatter DATE_FORMAT = DateTimeFormatter.ofPattern("yyyyMMdd");
    private static final DateTimeFormatter HOUR_FORMAT = DateTimeFormatter.ofPattern("HH");
    
    // STRESS TEST PARAMETERS
    private static final int MILLION_RECORDS = 1_000_000;
    private static final int BATCH_SIZE = 10_000;
    private static final int THREAD_COUNT = 10;
    private static final int TEST_DURATION_HOURS = 6; // Run for 6 hours
    private static final int DAYS_TO_SPAN = 30; // Span 30 days of data
    
    @Container
    static final MySQLContainer<?> mysql = new MySQLContainer<>("mysql:8.0.33")
            .withDatabaseName("stress_partition_db")
            .withUsername("stress_user")
            .withPassword("stress_pass")
            .withCommand("--innodb-buffer-pool-size=2G", 
                        "--innodb-log-file-size=1G",
                        "--max-connections=1000",
                        "--innodb-flush-log-at-trx-commit=2");
    
    private static ConnectionProvider connectionProvider;
    private static EntityMetadata<TestEntity, Long> entityMetadata;
    private static ExecutorService executorService;
    
    // Metrics collection
    private static final AtomicLong totalRecordsInserted = new AtomicLong(0);
    private static final AtomicLong totalInsertTime = new AtomicLong(0);
    private static final AtomicInteger partitionsCreated = new AtomicInteger(0);
    private static final AtomicInteger tablesCreated = new AtomicInteger(0);
    private static final Map<String, AtomicLong> hourlyDistribution = new ConcurrentHashMap<>();
    private static final Set<String> createdTables = ConcurrentHashMap.newKeySet();
    private static final LocalDateTime TEST_START_TIME = LocalDateTime.now().minusDays(DAYS_TO_SPAN);
    
    @BeforeAll
    static void setupStressTest() {
        logger.info("üöÄ INITIALIZING PARTITIONING STRESS TEST");
        logger.info("üìä Test Parameters:");
        logger.info("   ‚Ä¢ Records to insert: {}", MILLION_RECORDS);
        logger.info("   ‚Ä¢ Batch size: {}", BATCH_SIZE);
        logger.info("   ‚Ä¢ Thread count: {}", THREAD_COUNT);
        logger.info("   ‚Ä¢ Test duration: {} hours", TEST_DURATION_HOURS);
        logger.info("   ‚Ä¢ Days to span: {}", DAYS_TO_SPAN);
        
        String host = mysql.getHost();
        int port = mysql.getFirstMappedPort();
        String database = mysql.getDatabaseName();
        String username = mysql.getUsername();
        String password = mysql.getPassword();
        
        logger.info("üê¨ MySQL Container: {}:{}/{}", host, port, database);
        
        // Initialize connection provider with stress test settings
        connectionProvider = new ConnectionProvider(host, port, database, username, password);
        entityMetadata = new EntityMetadata<>(TestEntity.class, Long.class);
        executorService = Executors.newFixedThreadPool(THREAD_COUNT);
        
        // Initialize hourly distribution tracking
        for (int hour = 0; hour < 24; hour++) {
            hourlyDistribution.put(String.format("%02d", hour), new AtomicLong(0));
        }
        
        logger.info("‚úÖ Stress test initialization completed");
    }
    
    @Test
    @Order(1)
    @DisplayName("1. üî• MILLION RECORD INSERTION STRESS TEST")
    void testMillionRecordInsertion() throws Exception {
        logger.info("üî• STARTING MILLION RECORD INSERTION STRESS TEST");
        
        long startTime = System.currentTimeMillis();
        List<Future<InsertionResult>> futures = new ArrayList<>();
        
        // Distribute work across threads
        int recordsPerThread = MILLION_RECORDS / THREAD_COUNT;
        
        for (int threadId = 0; threadId < THREAD_COUNT; threadId++) {
            final int finalThreadId = threadId;
            final int startIndex = threadId * recordsPerThread;
            final int endIndex = (threadId == THREAD_COUNT - 1) ? MILLION_RECORDS : startIndex + recordsPerThread;
            
            Future<InsertionResult> future = executorService.submit(() -> 
                insertRecordsInBatches(finalThreadId, startIndex, endIndex));
            futures.add(future);
        }
        
        // Collect results
        long totalInserted = 0;
        long totalTime = 0;
        
        for (Future<InsertionResult> future : futures) {
            InsertionResult result = future.get();
            totalInserted += result.recordsInserted;
            totalTime += result.insertionTime;
            
            logger.info("üßµ Thread {} completed: {} records in {}ms", 
                result.threadId, result.recordsInserted, result.insertionTime);
        }
        
        long endTime = System.currentTimeMillis();
        long totalTestTime = endTime - startTime;
        
        // Verify results
        assertThat(totalInserted).isEqualTo(MILLION_RECORDS);
        
        logger.info("‚úÖ MILLION RECORD INSERTION COMPLETED");
        logger.info("üìä Results:");
        logger.info("   ‚Ä¢ Total records inserted: {}", totalInserted);
        logger.info("   ‚Ä¢ Total test time: {}ms ({} seconds)", totalTestTime, totalTestTime / 1000);
        logger.info("   ‚Ä¢ Average insertion rate: {} records/second", 
            (totalInserted * 1000) / totalTestTime);
        logger.info("   ‚Ä¢ Tables created: {}", tablesCreated.get());
        
        totalRecordsInserted.set(totalInserted);
        totalInsertTime.set(totalTestTime);
    }
    
    @Test
    @Order(2)
    @DisplayName("2. üèóÔ∏è PARTITION STRUCTURE VERIFICATION")
    void testPartitionStructureVerification() throws Exception {
        logger.info("üèóÔ∏è VERIFYING PARTITION STRUCTURES");
        
        Set<String> verifiedTables = new HashSet<>();
        int totalPartitionsFound = 0;
        
        try (Connection conn = connectionProvider.getConnection()) {
            // Get all created tables
            try (ResultSet rs = conn.getMetaData().getTables(null, mysql.getDatabaseName(), 
                "stress_test_%", new String[]{"TABLE"})) {
                
                while (rs.next()) {
                    String tableName = rs.getString("TABLE_NAME");
                    verifiedTables.add(tableName);
                    
                    // Verify table has partitions
                    int partitions = verifyTablePartitions(conn, tableName);
                    totalPartitionsFound += partitions;
                    
                    logger.debug("üìã Table {} has {} partitions", tableName, partitions);
                }
            }
        }
        
        logger.info("‚úÖ PARTITION STRUCTURE VERIFICATION COMPLETED");
        logger.info("üìä Results:");
        logger.info("   ‚Ä¢ Tables verified: {}", verifiedTables.size());
        logger.info("   ‚Ä¢ Total partitions found: {}", totalPartitionsFound);
        logger.info("   ‚Ä¢ Expected partitions per table: 24 (hourly)");
        
        // Verify we have tables and partitions
        assertThat(verifiedTables.size()).isGreaterThan(0);
        assertThat(totalPartitionsFound).isGreaterThan(0);
        
        createdTables.addAll(verifiedTables);
        partitionsCreated.set(totalPartitionsFound);
    }
    
    @Test
    @Order(3)
    @DisplayName("3. üéØ PARTITION PRUNING AND INDEX VERIFICATION")
    void testPartitionPruningAndIndexes() throws Exception {
        logger.info("üéØ TESTING PARTITION PRUNING AND INDEX VERIFICATION");
        
        Map<String, PartitionMetrics> partitionMetrics = new HashMap<>();
        
        try (Connection conn = connectionProvider.getConnection()) {
            for (String tableName : createdTables) {
                PartitionMetrics metrics = analyzePartitionUsage(conn, tableName);
                partitionMetrics.put(tableName, metrics);
                
                // Verify indexes exist
                verifyTableIndexes(conn, tableName);
                
                logger.debug("üîç Table {}: {} records across {} partitions", 
                    tableName, metrics.totalRecords, metrics.partitionsWithData);
            }
        }
        
        // Calculate statistics
        long totalRecordsVerified = partitionMetrics.values().stream()
            .mapToLong(m -> m.totalRecords)
            .sum();
        
        int totalPartitionsWithData = partitionMetrics.values().stream()
            .mapToInt(m -> m.partitionsWithData)
            .sum();
        
        logger.info("‚úÖ PARTITION PRUNING AND INDEX VERIFICATION COMPLETED");
        logger.info("üìä Results:");
        logger.info("   ‚Ä¢ Total records verified: {}", totalRecordsVerified);
        logger.info("   ‚Ä¢ Partitions with data: {}", totalPartitionsWithData);
        logger.info("   ‚Ä¢ Data distribution efficiency: {}%", 
            (totalPartitionsWithData * 100.0) / partitionsCreated.get());
        
        assertThat(totalRecordsVerified).isEqualTo(MILLION_RECORDS);
        assertThat(totalPartitionsWithData).isGreaterThan(0);
    }
    
    @Test
    @Order(4)
    @DisplayName("4. üå™Ô∏è CONCURRENT ACCESS STRESS TEST")
    void testConcurrentAccessStress() throws Exception {
        logger.info("üå™Ô∏è STARTING CONCURRENT ACCESS STRESS TEST");
        
        int concurrentThreads = 20;
        int operationsPerThread = 10_000;
        ExecutorService concurrentExecutor = Executors.newFixedThreadPool(concurrentThreads);
        
        List<Future<ConcurrentResult>> concurrentFutures = new ArrayList<>();
        
        for (int i = 0; i < concurrentThreads; i++) {
            final int threadId = i;
            Future<ConcurrentResult> future = concurrentExecutor.submit(() -> 
                performConcurrentOperations(threadId, operationsPerThread));
            concurrentFutures.add(future);
        }
        
        // Collect concurrent results
        long totalConcurrentOps = 0;
        long totalConcurrentTime = 0;
        int totalErrors = 0;
        
        for (Future<ConcurrentResult> future : concurrentFutures) {
            ConcurrentResult result = future.get();
            totalConcurrentOps += result.operationsCompleted;
            totalConcurrentTime += result.executionTime;
            totalErrors += result.errors;
        }
        
        concurrentExecutor.shutdown();
        
        logger.info("‚úÖ CONCURRENT ACCESS STRESS TEST COMPLETED");
        logger.info("üìä Results:");
        logger.info("   ‚Ä¢ Total concurrent operations: {}", totalConcurrentOps);
        logger.info("   ‚Ä¢ Total errors: {}", totalErrors);
        logger.info("   ‚Ä¢ Error rate: {}%", (totalErrors * 100.0) / totalConcurrentOps);
        logger.info("   ‚Ä¢ Average concurrent throughput: {} ops/second", 
            (totalConcurrentOps * 1000) / (totalConcurrentTime / concurrentThreads));
        
        // Verify error rate is acceptable (< 1%)
        double errorRate = (totalErrors * 100.0) / totalConcurrentOps;
        assertThat(errorRate).isLessThan(1.0);
    }
    
    @Test
    @Order(5)
    @DisplayName("5. üöÄ CORNER CASE STRESS TEST")
    void testCornerCases() throws Exception {
        logger.info("üöÄ TESTING CORNER CASES");
        
        List<CornerCaseTest> cornerCases = Arrays.asList(
            new CornerCaseTest("Leap Year February 29", 
                LocalDateTime.of(2024, 2, 29, 23, 59, 59)),
            new CornerCaseTest("New Year Midnight", 
                LocalDateTime.of(2024, 1, 1, 0, 0, 0)),
            new CornerCaseTest("Month Boundary", 
                LocalDateTime.of(2024, 3, 31, 23, 59, 59)),
            new CornerCaseTest("Hour Boundary", 
                LocalDateTime.of(2024, 6, 15, 23, 59, 59)),
            new CornerCaseTest("Daylight Saving Time", 
                LocalDateTime.of(2024, 3, 10, 2, 30, 0))
        );
        
        for (CornerCaseTest cornerCase : cornerCases) {
            logger.info("üß™ Testing corner case: {}", cornerCase.name);
            
            TestEntity entity = createTestEntity("CornerCase_" + cornerCase.name.replaceAll(" ", "_"), 
                cornerCase.timestamp);
            
            try (Connection conn = connectionProvider.getConnection()) {
                String tableName = "stress_test_" + cornerCase.timestamp.toLocalDate().format(DATE_FORMAT);
                
                // Ensure table exists
                createTableIfNotExists(conn, tableName);
                
                // Insert record
                insertSingleRecord(conn, tableName, entity);
                
                // Verify record can be retrieved
                TestEntity retrieved = retrieveRecord(conn, tableName, entity.getName());
                assertThat(retrieved).isNotNull();
                assertThat(retrieved.getName()).isEqualTo(entity.getName());
                
                logger.debug("‚úÖ Corner case {} handled successfully", cornerCase.name);
            }
        }
        
        logger.info("‚úÖ CORNER CASE TESTING COMPLETED - All cases handled successfully");
    }
    
    // Helper Methods
    
    private InsertionResult insertRecordsInBatches(int threadId, int startIndex, int endIndex) {
        long threadStartTime = System.currentTimeMillis();
        int recordsInserted = 0;
        
        try (Connection conn = connectionProvider.getConnection()) {
            conn.setAutoCommit(false);
            
            for (int i = startIndex; i < endIndex; i += BATCH_SIZE) {
                int batchEnd = Math.min(i + BATCH_SIZE, endIndex);
                
                Map<String, List<TestEntity>> batchesByTable = new HashMap<>();
                
                // Group entities by table
                for (int j = i; j < batchEnd; j++) {
                    TestEntity entity = createStressTestEntity(threadId, j);
                    String tableName = "stress_test_" + entity.getCreatedAt().toLocalDate().format(DATE_FORMAT);
                    
                    batchesByTable.computeIfAbsent(tableName, k -> new ArrayList<>()).add(entity);
                }
                
                // Insert batches by table
                for (Map.Entry<String, List<TestEntity>> entry : batchesByTable.entrySet()) {
                    String tableName = entry.getKey();
                    List<TestEntity> entities = entry.getValue();
                    
                    createTableIfNotExists(conn, tableName);
                    insertBatch(conn, tableName, entities);
                    recordsInserted += entities.size();
                }
                
                conn.commit();
                
                if (i % (BATCH_SIZE * 10) == 0) {
                    logger.debug("üßµ Thread {} progress: {} records inserted", threadId, recordsInserted);
                }
            }
            
        } catch (Exception e) {
            logger.error("‚ùå Error in thread {}", threadId, e);
            throw new RuntimeException("Thread " + threadId + " failed", e);
        }
        
        long threadEndTime = System.currentTimeMillis();
        return new InsertionResult(threadId, recordsInserted, threadEndTime - threadStartTime);
    }
    
    private TestEntity createStressTestEntity(int threadId, int index) {
        // Distribute across time range
        long totalMinutes = DAYS_TO_SPAN * 24 * 60;
        long minuteOffset = (index % totalMinutes);
        LocalDateTime timestamp = TEST_START_TIME.plusMinutes(minuteOffset);
        
        // Track hourly distribution
        String hour = timestamp.format(HOUR_FORMAT);
        hourlyDistribution.get(hour).incrementAndGet();
        
        return new TestEntity(
            "StressUser_T" + threadId + "_" + index,
            "stress" + threadId + "_" + index + "@test.com",
            index % 3 == 0 ? "ACTIVE" : (index % 3 == 1 ? "PENDING" : "INACTIVE"),
            20 + (index % 60),
            new BigDecimal("100.00").add(new BigDecimal(index % 10000)),
            index % 2 == 0,
            "Stress test entity " + index + " from thread " + threadId,
            timestamp
        );
    }
    
    private void createTableIfNotExists(Connection conn, String tableName) throws SQLException {
        String createTableSQL = String.format(entityMetadata.getCreateTableSQL(), tableName);
        
        try (Statement stmt = conn.createStatement()) {
            stmt.executeUpdate(createTableSQL);
            
            // Add partitioning if not exists
            addHourlyPartitioning(conn, tableName);
            
            tablesCreated.incrementAndGet();
        } catch (SQLException e) {
            if (!e.getMessage().contains("already exists")) {
                throw e;
            }
        }
    }
    
    private void addHourlyPartitioning(Connection conn, String tableName) throws SQLException {
        try (Statement stmt = conn.createStatement()) {
            // Create partitions for each hour (0-23)
            StringBuilder partitionSQL = new StringBuilder();
            partitionSQL.append("ALTER TABLE ").append(tableName).append(" PARTITION BY RANGE (HOUR(created_at)) (");
            
            for (int hour = 0; hour < 24; hour++) {
                if (hour > 0) partitionSQL.append(", ");
                partitionSQL.append("PARTITION h").append(String.format("%02d", hour))
                          .append(" VALUES LESS THAN (").append(hour + 1).append(")");
            }
            partitionSQL.append(")");
            
            stmt.executeUpdate(partitionSQL.toString());
        } catch (SQLException e) {
            if (!e.getMessage().contains("already exists") && 
                !e.getMessage().contains("already partitioned")) {
                logger.debug("Partitioning info for {}: {}", tableName, e.getMessage());
            }
        }
    }
    
    private void insertBatch(Connection conn, String tableName, List<TestEntity> entities) throws SQLException {
        String insertSQL = String.format(entityMetadata.getInsertSQL(), tableName);
        
        try (PreparedStatement pstmt = conn.prepareStatement(insertSQL, Statement.RETURN_GENERATED_KEYS)) {
            for (TestEntity entity : entities) {
                entityMetadata.setInsertParameters(pstmt, entity);
                pstmt.addBatch();
            }
            
            int[] results = pstmt.executeBatch();
            
            // Set generated IDs
            try (ResultSet generatedKeys = pstmt.getGeneratedKeys()) {
                int i = 0;
                while (generatedKeys.next() && i < entities.size()) {
                    entities.get(i++).setId(generatedKeys.getLong(1));
                }
            }
        }
    }
    
    private int verifyTablePartitions(Connection conn, String tableName) throws SQLException {
        String partitionQuery = "SELECT COUNT(*) as partition_count FROM information_schema.partitions " +
                               "WHERE table_schema = ? AND table_name = ? AND partition_name IS NOT NULL";
        
        try (PreparedStatement pstmt = conn.prepareStatement(partitionQuery)) {
            pstmt.setString(1, mysql.getDatabaseName());
            pstmt.setString(2, tableName);
            
            try (ResultSet rs = pstmt.executeQuery()) {
                if (rs.next()) {
                    return rs.getInt("partition_count");
                }
            }
        }
        return 0;
    }
    
    private PartitionMetrics analyzePartitionUsage(Connection conn, String tableName) throws SQLException {
        String analysisQuery = "SELECT partition_name, table_rows FROM information_schema.partitions " +
                              "WHERE table_schema = ? AND table_name = ? AND partition_name IS NOT NULL";
        
        PartitionMetrics metrics = new PartitionMetrics();
        
        try (PreparedStatement pstmt = conn.prepareStatement(analysisQuery)) {
            pstmt.setString(1, mysql.getDatabaseName());
            pstmt.setString(2, tableName);
            
            try (ResultSet rs = pstmt.executeQuery()) {
                while (rs.next()) {
                    long rows = rs.getLong("table_rows");
                    if (rows > 0) {
                        metrics.partitionsWithData++;
                    }
                    metrics.totalRecords += rows;
                }
            }
        }
        
        return metrics;
    }
    
    private void verifyTableIndexes(Connection conn, String tableName) throws SQLException {
        String indexQuery = "SELECT COUNT(*) as index_count FROM information_schema.statistics " +
                           "WHERE table_schema = ? AND table_name = ? AND column_name = 'created_at'";
        
        try (PreparedStatement pstmt = conn.prepareStatement(indexQuery)) {
            pstmt.setString(1, mysql.getDatabaseName());
            pstmt.setString(2, tableName);
            
            try (ResultSet rs = pstmt.executeQuery()) {
                if (rs.next()) {
                    int indexCount = rs.getInt("index_count");
                    assertThat(indexCount).isGreaterThan(0);
                }
            }
        }
    }
    
    private ConcurrentResult performConcurrentOperations(int threadId, int operations) {
        long startTime = System.currentTimeMillis();
        int completed = 0;
        int errors = 0;
        
        try (Connection conn = connectionProvider.getConnection()) {
            for (int i = 0; i < operations; i++) {
                try {
                    // Mix of read and write operations
                    if (i % 10 == 0) {
                        // Write operation
                        TestEntity entity = createStressTestEntity(threadId, i);
                        String tableName = "stress_test_" + entity.getCreatedAt().toLocalDate().format(DATE_FORMAT);
                        insertSingleRecord(conn, tableName, entity);
                    } else {
                        // Read operation - query random table
                        queryRandomTable(conn);
                    }
                    completed++;
                } catch (Exception e) {
                    errors++;
                    logger.debug("Concurrent operation error in thread {}: {}", threadId, e.getMessage());
                }
            }
        } catch (Exception e) {
            logger.error("Fatal error in concurrent thread {}", threadId, e);
        }
        
        long endTime = System.currentTimeMillis();
        return new ConcurrentResult(threadId, completed, errors, endTime - startTime);
    }
    
    private void insertSingleRecord(Connection conn, String tableName, TestEntity entity) throws SQLException {
        createTableIfNotExists(conn, tableName);
        
        String insertSQL = String.format(entityMetadata.getInsertSQL(), tableName);
        try (PreparedStatement pstmt = conn.prepareStatement(insertSQL, Statement.RETURN_GENERATED_KEYS)) {
            entityMetadata.setInsertParameters(pstmt, entity);
            pstmt.executeUpdate();
            
            try (ResultSet generatedKeys = pstmt.getGeneratedKeys()) {
                if (generatedKeys.next()) {
                    entity.setId(generatedKeys.getLong(1));
                }
            }
        }
    }
    
    private TestEntity retrieveRecord(Connection conn, String tableName, String name) throws SQLException {
        String selectSQL = "SELECT * FROM " + tableName + " WHERE name = ?";
        try (PreparedStatement pstmt = conn.prepareStatement(selectSQL)) {
            pstmt.setString(1, name);
            
            try (ResultSet rs = pstmt.executeQuery()) {
                if (rs.next()) {
                    return entityMetadata.mapResultSet(rs);
                }
            }
        }
        return null;
    }
    
    private void queryRandomTable(Connection conn) throws SQLException {
        if (createdTables.isEmpty()) return;
        
        String[] tableArray = createdTables.toArray(new String[0]);
        String randomTable = tableArray[(int)(Math.random() * tableArray.length)];
        
        String countQuery = "SELECT COUNT(*) FROM " + randomTable;
        try (Statement stmt = conn.createStatement();
             ResultSet rs = stmt.executeQuery(countQuery)) {
            rs.next(); // Just execute the query, don't need the result
        }
    }
    
    private TestEntity createTestEntity(String name, LocalDateTime timestamp) {
        return new TestEntity(
            name,
            name.toLowerCase() + "@cornercase.test",
            "ACTIVE",
            30,
            new BigDecimal("1000.00"),
            true,
            "Corner case test entity: " + name,
            timestamp
        );
    }
    
    @AfterAll
    static void printFinalResults() {
        logger.info("üéØ PARTITIONING STRESS TEST FINAL RESULTS");
        logger.info("=".repeat(60));
        logger.info("üìä PERFORMANCE METRICS:");
        logger.info("   ‚Ä¢ Total records processed: {}", totalRecordsInserted.get());
        logger.info("   ‚Ä¢ Total test duration: {}ms", totalInsertTime.get());
        logger.info("   ‚Ä¢ Tables created: {}", tablesCreated.get());
        logger.info("   ‚Ä¢ Partitions created: {}", partitionsCreated.get());
        logger.info("   ‚Ä¢ Average throughput: {} records/second", 
            (totalRecordsInserted.get() * 1000) / Math.max(1, totalInsertTime.get()));
        
        logger.info("‚è∞ HOURLY DATA DISTRIBUTION:");
        hourlyDistribution.entrySet().stream()
            .sorted(Map.Entry.comparingByKey())
            .forEach(entry -> logger.info("   ‚Ä¢ Hour {}: {} records", 
                entry.getKey(), entry.getValue().get()));
        
        logger.info("üèÜ STRESS TEST COMPLETED SUCCESSFULLY!");
        
        if (executorService != null && !executorService.isShutdown()) {
            executorService.shutdown();
        }
    }
    
    // Result classes
    static class InsertionResult {
        final int threadId;
        final int recordsInserted;
        final long insertionTime;
        
        InsertionResult(int threadId, int recordsInserted, long insertionTime) {
            this.threadId = threadId;
            this.recordsInserted = recordsInserted;
            this.insertionTime = insertionTime;
        }
    }
    
    static class PartitionMetrics {
        long totalRecords = 0;
        int partitionsWithData = 0;
    }
    
    static class ConcurrentResult {
        final int threadId;
        final int operationsCompleted;
        final int errors;
        final long executionTime;
        
        ConcurrentResult(int threadId, int operationsCompleted, int errors, long executionTime) {
            this.threadId = threadId;
            this.operationsCompleted = operationsCompleted;
            this.errors = errors;
            this.executionTime = executionTime;
        }
    }
    
    static class CornerCaseTest {
        final String name;
        final LocalDateTime timestamp;
        
        CornerCaseTest(String name, LocalDateTime timestamp) {
            this.name = name;
            this.timestamp = timestamp;
        }
    }
}