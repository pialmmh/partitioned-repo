package com.telcobright.splitverse.tests;

import com.telcobright.api.ShardingRepository;
import com.telcobright.core.config.DataSourceConfig;
import com.telcobright.core.entity.ShardingEntity;
import com.telcobright.core.enums.PartitionColumnType;
import com.telcobright.core.enums.PartitionRange;
import com.telcobright.core.enums.ShardingStrategy;
import com.telcobright.core.repository.SplitVerseRepository;
import com.telcobright.splitverse.config.RepositoryMode;
import com.telcobright.core.annotation.*;
import org.junit.jupiter.api.*;

import java.sql.SQLException;
import java.time.LocalDateTime;
import java.util.*;

import static org.junit.jupiter.api.Assertions.*;

/**
 * Comprehensive integration tests for all sharding strategy combinations.
 * Tests each combination with real MySQL database operations.
 */
@TestMethodOrder(MethodOrderer.OrderAnnotation.class)
public class ComprehensiveStrategyTest {

    // Test entity with all supported field types
    @Table(name = "test_entity")
    public static class TestEntity implements ShardingEntity<LocalDateTime> {
        @Id(autoGenerated = false)
        @Column(name = "id")
        private String id;

        @ShardingKey
        @Column(name = "created_at")
        private LocalDateTime createdAt;

        @Column(name = "sequence_number")
        private Long sequenceNumber;

        @Column(name = "category_id")
        private Integer categoryId;

        @Column(name = "amount")
        private Double amount;

        @Column(name = "customer_id")
        private String customerId;

        @Column(name = "data")
        private String data;

        @Override
        public String getId() { return id; }
        @Override
        public void setId(String id) { this.id = id; }
        public LocalDateTime getCreatedAt() { return createdAt; }
        public void setCreatedAt(LocalDateTime createdAt) { this.createdAt = createdAt; }

    @Override
    public LocalDateTime getPartitionColValue() {
        return createdAt;
    }

    @Override
    public void setPartitionColValue(LocalDateTime value) {
        this.createdAt = value;
    }

        public Long getSequenceNumber() { return sequenceNumber; }
        public void setSequenceNumber(Long sequenceNumber) { this.sequenceNumber = sequenceNumber; }
        public Integer getCategoryId() { return categoryId; }
        public void setCategoryId(Integer categoryId) { this.categoryId = categoryId; }
        public Double getAmount() { return amount; }
        public void setAmount(Double amount) { this.amount = amount; }
        public String getCustomerId() { return customerId; }
        public void setCustomerId(String customerId) { this.customerId = customerId; }
        public String getData() { return data; }
        public void setData(String data) { this.data = data; }
    }

    private static final String TEST_DB = "split_verse_comp_test";
    private static Map<String, ShardingRepository<TestEntity, LocalDateTime>> repositories = new HashMap<>();
    private static List<String> insertedIds = new ArrayList<>();

    @BeforeAll
    public static void setupDatabase() throws SQLException {
        // Verify MySQL connection
        if (!TestDatabaseSetup.verifyMySQLConnection()) {
            fail("MySQL is not available. Please ensure MySQL is running at 127.0.0.1:3306");
        }

        // Create test database
        TestDatabaseSetup.createTestDatabase(TEST_DB);
    }

    @AfterAll
    public static void cleanup() {
        // Shutdown all repositories
        for (ShardingRepository<TestEntity, LocalDateTime> repo : repositories.values()) {
            repo.shutdown();
        }

        // Cleanup test databases
        TestDatabaseSetup.cleanupTestDatabases();
    }

    // ==================== SINGLE_KEY_HASH Tests ====================

    @Test
    @Order(1)
    public void testSingleKeyHashStrategy() throws SQLException {
        String strategyName = "SINGLE_KEY_HASH";
        ShardingRepository<TestEntity, LocalDateTime> repo = createRepository(
            strategyName,
            ShardingStrategy.SINGLE_KEY_HASH,
            null, null, null
        );

        // Test CRUD operations
        TestEntity entity = createTestEntity();
        performCrudOperations(repo, entity, strategyName);
    }

    // ==================== DUAL_KEY_HASH_RANGE + LOCAL_DATE_TIME Tests ====================

    @Test
    @Order(2)
    public void testDualKeyHashRange_DateTime_Daily() throws SQLException {
        testDateTimePartitioning(PartitionRange.DAILY, "DAILY");
    }

    @Test
    @Order(3)
    public void testDualKeyHashRange_DateTime_Hourly() throws SQLException {
        testDateTimePartitioning(PartitionRange.HOURLY, "HOURLY");
    }

    @Test
    @Order(4)
    public void testDualKeyHashRange_DateTime_Monthly() throws SQLException {
        testDateTimePartitioning(PartitionRange.MONTHLY, "MONTHLY");
    }

    @Test
    @Order(5)
    public void testDualKeyHashRange_DateTime_Yearly() throws SQLException {
        testDateTimePartitioning(PartitionRange.YEARLY, "YEARLY");
    }

    private void testDateTimePartitioning(PartitionRange range, String rangeName) throws SQLException {
        String strategyName = "DUAL_KEY_HASH_RANGE_DateTime_" + rangeName;
        ShardingRepository<TestEntity, LocalDateTime> repo = createRepository(
            strategyName,
            ShardingStrategy.DUAL_KEY_HASH_RANGE,
            "created_at",
            PartitionColumnType.LOCAL_DATE_TIME,
            range
        );

        // Test with different dates
        LocalDateTime now = LocalDateTime.now();
        LocalDateTime yesterday = now.minusDays(1);
        LocalDateTime tomorrow = now.plusDays(1);

        // Insert entities across different time periods
        TestEntity entity1 = createTestEntity();
        entity1.setCreatedAt(yesterday);
        repo.insert(entity1);
        insertedIds.add(entity1.getId());

        TestEntity entity2 = createTestEntity();
        entity2.setCreatedAt(now);
        repo.insert(entity2);
        insertedIds.add(entity2.getId());

        TestEntity entity3 = createTestEntity();
        entity3.setCreatedAt(tomorrow);
        repo.insert(entity3);
        insertedIds.add(entity3.getId());

        // Test date range queries
        List<TestEntity> results = repo.findAllByDateRange(
            yesterday.minusHours(1),
            tomorrow.plusHours(1)
        );
        assertTrue(results.size() >= 3, "Should find all 3 entities in date range");

        // Test specific date range
        List<TestEntity> todayResults = repo.findAllByDateRange(
            now.withHour(0).withMinute(0).withSecond(0),
            now.withHour(23).withMinute(59).withSecond(59)
        );
        assertTrue(todayResults.size() >= 1, "Should find today's entity");

        System.out.println("✓ " + strategyName + " test passed with " + results.size() + " entities");
    }

    // ==================== DUAL_KEY_HASH_RANGE + LONG Tests ====================

    @Test
    @Order(6)
    public void testDualKeyHashRange_Long_1K() throws SQLException {
        testLongPartitioning(PartitionRange.VALUE_RANGE_1K, "1K", 0L, 999L, 1000L);
    }

    @Test
    @Order(7)
    public void testDualKeyHashRange_Long_100K() throws SQLException {
        testLongPartitioning(PartitionRange.VALUE_RANGE_100K, "100K", 0L, 99999L, 100000L);
    }

    @Test
    @Order(8)
    public void testDualKeyHashRange_Long_1M() throws SQLException {
        testLongPartitioning(PartitionRange.VALUE_RANGE_1M, "1M", 0L, 999999L, 1000000L);
    }

    private void testLongPartitioning(PartitionRange range, String rangeName,
                                      Long val1, Long val2, Long val3) throws SQLException {
        String strategyName = "DUAL_KEY_HASH_RANGE_Long_" + rangeName;
        ShardingRepository<TestEntity, LocalDateTime> repo = createRepository(
            strategyName,
            ShardingStrategy.DUAL_KEY_HASH_RANGE,
            "sequence_number",
            PartitionColumnType.LONG,
            range
        );

        // Insert entities with different sequence numbers (different partitions)
        TestEntity entity1 = createTestEntity();
        entity1.setSequenceNumber(val1); // First range
        repo.insert(entity1);
        insertedIds.add(entity1.getId());

        TestEntity entity2 = createTestEntity();
        entity2.setSequenceNumber(val2); // Still in first range
        repo.insert(entity2);
        insertedIds.add(entity2.getId());

        TestEntity entity3 = createTestEntity();
        entity3.setSequenceNumber(val3); // Second range
        repo.insert(entity3);
        insertedIds.add(entity3.getId());

        // Verify retrieval
        TestEntity found1 = repo.findById(entity1.getId());
        assertNotNull(found1);
        assertEquals(val1, found1.getSequenceNumber());

        TestEntity found3 = repo.findById(entity3.getId());
        assertNotNull(found3);
        assertEquals(val3, found3.getSequenceNumber());

        System.out.println("✓ " + strategyName + " test passed with value-based partitioning");
    }

    // ==================== DUAL_KEY_HASH_RANGE + INTEGER Tests ====================

    @Test
    @Order(9)
    public void testDualKeyHashRange_Integer() throws SQLException {
        String strategyName = "DUAL_KEY_HASH_RANGE_Integer";
        ShardingRepository<TestEntity, LocalDateTime> repo = createRepository(
            strategyName,
            ShardingStrategy.DUAL_KEY_HASH_RANGE,
            "category_id",
            PartitionColumnType.INTEGER,
            PartitionRange.VALUE_RANGE_10K
        );

        // Insert entities with different category IDs
        for (int i = 0; i < 5; i++) {
            TestEntity entity = createTestEntity();
            entity.setCategoryId(i * 10000); // Different partitions
            repo.insert(entity);
            insertedIds.add(entity.getId());

            // Verify
            TestEntity found = repo.findById(entity.getId());
            assertNotNull(found);
            assertEquals(Integer.valueOf(i * 10000), found.getCategoryId());
        }

        System.out.println("✓ " + strategyName + " test passed");
    }

    // ==================== DUAL_KEY_HASH_RANGE + DOUBLE Tests ====================

    @Test
    @Order(10)
    public void testDualKeyHashRange_Double() throws SQLException {
        String strategyName = "DUAL_KEY_HASH_RANGE_Double";
        ShardingRepository<TestEntity, LocalDateTime> repo = createRepository(
            strategyName,
            ShardingStrategy.DUAL_KEY_HASH_RANGE,
            "amount",
            PartitionColumnType.DOUBLE,
            PartitionRange.VALUE_RANGE_1K
        );

        // Insert entities with different amounts
        double[] amounts = {100.50, 999.99, 1000.00, 5000.75};
        for (double amount : amounts) {
            TestEntity entity = createTestEntity();
            entity.setAmount(amount);
            repo.insert(entity);
            insertedIds.add(entity.getId());

            // Verify
            TestEntity found = repo.findById(entity.getId());
            assertNotNull(found);
            assertEquals(amount, found.getAmount(), 0.01);
        }

        System.out.println("✓ " + strategyName + " test passed");
    }

    // ==================== DUAL_KEY_HASH_HASH + STRING Tests ====================

    @Test
    @Order(11)
    public void testDualKeyHashHash_String_4Buckets() throws SQLException {
        testHashPartitioning(PartitionRange.HASH_4, "4");
    }

    @Test
    @Order(12)
    public void testDualKeyHashHash_String_16Buckets() throws SQLException {
        testHashPartitioning(PartitionRange.HASH_16, "16");
    }

    @Test
    @Order(13)
    public void testDualKeyHashHash_String_32Buckets() throws SQLException {
        testHashPartitioning(PartitionRange.HASH_32, "32");
    }

    private void testHashPartitioning(PartitionRange range, String buckets) throws SQLException {
        String strategyName = "DUAL_KEY_HASH_HASH_String_" + buckets;
        ShardingRepository<TestEntity, LocalDateTime> repo = createRepository(
            strategyName,
            ShardingStrategy.DUAL_KEY_HASH_HASH,
            "customer_id",
            PartitionColumnType.STRING,
            range
        );

        // Insert entities with different customer IDs (will be hashed to different buckets)
        String[] customerIds = {"customer_001", "customer_002", "customer_003", "customer_xyz", "customer_abc"};
        for (String customerId : customerIds) {
            TestEntity entity = createTestEntity();
            entity.setCustomerId(customerId);
            repo.insert(entity);
            insertedIds.add(entity.getId());

            // Verify
            TestEntity found = repo.findById(entity.getId());
            assertNotNull(found);
            assertEquals(customerId, found.getCustomerId());
        }

        System.out.println("✓ " + strategyName + " test passed with " + buckets + " hash buckets");
    }

    // ==================== Batch Operations Test ====================

    @Test
    @Order(14)
    public void testBatchOperationsAcrossPartitions() throws SQLException {
        String strategyName = "BATCH_OPS";
        ShardingRepository<TestEntity, LocalDateTime> repo = createRepository(
            strategyName,
            ShardingStrategy.DUAL_KEY_HASH_RANGE,
            "created_at",
            PartitionColumnType.LOCAL_DATE_TIME,
            PartitionRange.DAILY
        );

        // Create batch of entities across different days
        List<TestEntity> batch = new ArrayList<>();
        LocalDateTime baseTime = LocalDateTime.now();

        for (int i = -2; i <= 2; i++) {
            for (int j = 0; j < 3; j++) {
                TestEntity entity = createTestEntity();
                entity.setCreatedAt(baseTime.plusDays(i));
                batch.add(entity);
                insertedIds.add(entity.getId());
            }
        }

        // Batch insert
        repo.insertMultiple(batch);

        // Verify all were inserted
        for (TestEntity entity : batch) {
            TestEntity found = repo.findById(entity.getId());
            assertNotNull(found, "Entity should be found: " + entity.getId());
        }

        // Test batch retrieval
        List<String> batchIds = batch.stream()
            .limit(5)
            .map(TestEntity::getId)
            .toList();

        List<TestEntity> foundBatch = repo.findAllByIdsAndDateRange(
            batchIds,
            baseTime.minusDays(3),
            baseTime.plusDays(3)
        );
        assertEquals(5, foundBatch.size(), "Should find all 5 entities");

        System.out.println("✓ Batch operations test passed with " + batch.size() + " entities");
    }

    // ==================== Cursor-based Pagination Test ====================

    @Test
    @Order(15)
    public void testCursorBasedPagination() throws SQLException {
        String strategyName = "CURSOR_PAGINATION";
        ShardingRepository<TestEntity, LocalDateTime> repo = createRepository(
            strategyName,
            ShardingStrategy.SINGLE_KEY_HASH,
            null, null, null
        );

        // Insert multiple entities
        List<String> ids = new ArrayList<>();
        for (int i = 0; i < 10; i++) {
            TestEntity entity = createTestEntity();
            repo.insert(entity);
            ids.add(entity.getId());
            insertedIds.add(entity.getId());
        }

        // Sort IDs for verification
        Collections.sort(ids);

        // Test cursor-based pagination
        String cursor = "";
        List<String> paginatedIds = new ArrayList<>();
        int batchSize = 3;

        while (true) {
            List<TestEntity> batch = repo.findBatchByIdGreaterThan(cursor, batchSize);
            if (batch.isEmpty()) break;

            for (TestEntity entity : batch) {
                paginatedIds.add(entity.getId());
            }

            cursor = batch.get(batch.size() - 1).getId();
        }

        // Verify we got all entities
        assertTrue(paginatedIds.size() >= 10, "Should retrieve all entities via pagination");

        System.out.println("✓ Cursor-based pagination test passed with " + paginatedIds.size() + " entities");
    }

    // ==================== DELETE Operations Test ====================

    @Test
    @Order(16)
    public void testDeleteOperations() throws SQLException {
        String strategyName = "DELETE_OPS";
        ShardingRepository<TestEntity, LocalDateTime> repo = createRepository(
            strategyName,
            ShardingStrategy.DUAL_KEY_HASH_RANGE,
            "created_at",
            PartitionColumnType.LOCAL_DATE_TIME,
            PartitionRange.DAILY
        );

        // Insert test entities
        TestEntity entity1 = createTestEntity();
        repo.insert(entity1);

        TestEntity entity2 = createTestEntity();
        repo.insert(entity2);

        TestEntity entity3 = createTestEntity();
        entity3.setCreatedAt(LocalDateTime.now().minusDays(1));
        repo.insert(entity3);

        // Test deleteById
        repo.deleteById(entity1.getId());
        TestEntity deleted = repo.findById(entity1.getId());
        assertNull(deleted, "Entity should be deleted");

        // Test deleteByIdAndDateRange
        LocalDateTime now = LocalDateTime.now();
        repo.deleteByIdAndDateRange(
            entity2.getId(),
            now.minusHours(1),
            now.plusHours(1)
        );
        deleted = repo.findById(entity2.getId());
        assertNull(deleted, "Entity should be deleted by date range");

        // Test deleteAllByDateRange
        repo.deleteAllByDateRange(
            LocalDateTime.now().minusDays(2),
            LocalDateTime.now().minusHours(12)
        );
        deleted = repo.findById(entity3.getId());
        assertNull(deleted, "Entity should be deleted by date range");

        System.out.println("✓ Delete operations test passed");
    }

    // ==================== UPDATE Operations Test ====================

    @Test
    @Order(17)
    public void testUpdateOperations() throws SQLException {
        String strategyName = "UPDATE_OPS";
        ShardingRepository<TestEntity, LocalDateTime> repo = createRepository(
            strategyName,
            ShardingStrategy.DUAL_KEY_HASH_RANGE,
            "created_at",
            PartitionColumnType.LOCAL_DATE_TIME,
            PartitionRange.DAILY
        );

        // Insert test entity
        TestEntity entity = createTestEntity();
        entity.setData("Original Data");
        repo.insert(entity);
        insertedIds.add(entity.getId());

        // Update entity
        entity.setData("Updated Data");
        entity.setAmount(999.99);
        repo.updateById(entity.getId(), entity);

        // Verify update
        TestEntity updated = repo.findById(entity.getId());
        assertNotNull(updated);
        assertEquals("Updated Data", updated.getData());
        assertEquals(999.99, updated.getAmount(), 0.01);

        // Test updateByIdAndDateRange
        entity.setData("Range Updated");
        LocalDateTime now = LocalDateTime.now();
        repo.updateByIdAndDateRange(
            entity.getId(),
            entity,
            now.minusHours(1),
            now.plusHours(1)
        );

        updated = repo.findById(entity.getId());
        assertEquals("Range Updated", updated.getData());

        System.out.println("✓ Update operations test passed");
    }

    // ==================== Helper Methods ====================

    private ShardingRepository<TestEntity, LocalDateTime> createRepository(
        String name,
        ShardingStrategy strategy,
        String partitionColumn,
        PartitionColumnType columnType,
        PartitionRange range) {

        SplitVerseRepository.Builder<TestEntity, LocalDateTime> builder = SplitVerseRepository.<TestEntity, LocalDateTime>builder()
            .withEntityClass(TestEntity.class)
            .withTableName("test_" + name.toLowerCase().replace("-", "_"))
            .withShardingStrategy(strategy)
            .withRepositoryMode(RepositoryMode.MULTI_TABLE)
            .withRetentionDays(7)
            .withIdSize(22)
            .withDataSources(Arrays.asList(
                DataSourceConfig.create("127.0.0.1", 3306, TEST_DB, "root", "123456")
            ));

        if (strategy != ShardingStrategy.SINGLE_KEY_HASH) {
            builder.withPartitionColumn(partitionColumn, columnType)
                   .withPartitionRange(range);
        }

        ShardingRepository<TestEntity, LocalDateTime> repo = builder.build();
        repositories.put(name, repo);
        return repo;
    }

    private TestEntity createTestEntity() {
        TestEntity entity = new TestEntity();
        entity.setId(UUID.randomUUID().toString().replace("-", "").substring(0, 22));
        entity.setCreatedAt(LocalDateTime.now());
        entity.setSequenceNumber(System.currentTimeMillis());
        entity.setCategoryId((int) (Math.random() * 100));
        entity.setAmount(Math.random() * 1000);
        entity.setCustomerId("customer_" + UUID.randomUUID().toString().substring(0, 8));
        entity.setData("Test data " + System.currentTimeMillis());
        return entity;
    }

    private void performCrudOperations(ShardingRepository<TestEntity, LocalDateTime> repo,
                                       TestEntity entity,
                                       String strategyName) throws SQLException {
        // INSERT
        repo.insert(entity);
        insertedIds.add(entity.getId());

        // SELECT
        TestEntity found = repo.findById(entity.getId());
        assertNotNull(found, "Entity should be found after insert");
        assertEquals(entity.getId(), found.getId());

        // UPDATE
        entity.setData("Updated data");
        repo.updateById(entity.getId(), entity);

        found = repo.findById(entity.getId());
        assertEquals("Updated data", found.getData(), "Data should be updated");

        // DELETE
        repo.deleteById(entity.getId());
        found = repo.findById(entity.getId());
        assertNull(found, "Entity should be null after delete");

        System.out.println("✓ " + strategyName + " CRUD operations test passed");
    }
}