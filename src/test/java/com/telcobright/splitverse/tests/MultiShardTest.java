package com.telcobright.splitverse.tests;

import com.telcobright.api.ShardingRepository;
import com.telcobright.core.config.DataSourceConfig;
import com.telcobright.core.entity.ShardingEntity;
import com.telcobright.core.enums.PartitionColumnType;
import com.telcobright.core.enums.PartitionRange;
import com.telcobright.core.enums.ShardingStrategy;
import com.telcobright.core.repository.SplitVerseRepository;
import com.telcobright.splitverse.config.RepositoryMode;
import com.telcobright.core.annotation.*;
import org.junit.jupiter.api.*;

import java.sql.SQLException;
import java.time.LocalDateTime;
import java.util.*;
import java.util.concurrent.*;

import static org.junit.jupiter.api.Assertions.*;

/**
 * Tests for multi-shard scenarios with 3+ databases.
 * Verifies proper distribution and routing across multiple shards.
 */
@TestMethodOrder(MethodOrderer.OrderAnnotation.class)
public class MultiShardTest {

    @Table(name = "orders")
    public static class OrderEntity implements ShardingEntity<LocalDateTime> {
        @Id(autoGenerated = false)
        @Column(name = "id")
        private String id;

        @ShardingKey
        @Column(name = "created_at")
        private LocalDateTime createdAt;

        @Column(name = "customer_id")
        private String customerId;

        @Column(name = "amount")
        private Double amount;

        @Column(name = "status")
        private String status;

        @Override
        public String getId() { return id; }
        @Override
        public void setId(String id) { this.id = id; }
        @Override
        public LocalDateTime getCreatedAt() { return createdAt; }
        @Override
        public void setCreatedAt(LocalDateTime createdAt) { this.createdAt = createdAt; }

    @Override
    public LocalDateTime getPartitionColValue() {
        return createdAt;
    }

    @Override
    public void setPartitionColValue(LocalDateTime value) {
        this.createdAt = value;
    }

        public String getCustomerId() { return customerId; }
        public void setCustomerId(String customerId) { this.customerId = customerId; }
        public Double getAmount() { return amount; }
        public void setAmount(Double amount) { this.amount = amount; }
        public String getStatus() { return status; }
        public void setStatus(String status) { this.status = status; }
    }

    private static final int SHARD_COUNT = 3;
    private static List<String> testDatabases;
    private static ShardingRepository<OrderEntity, LocalDateTime> multiShardRepo;
    private static Map<String, List<String>> idsByShard = new HashMap<>();

    @BeforeAll
    public static void setup() throws SQLException {
        // Verify MySQL connection
        if (!TestDatabaseSetup.verifyMySQLConnection()) {
            fail("MySQL is not available");
        }

        // Create test databases for each shard
        testDatabases = TestDatabaseSetup.createTestDatabases(SHARD_COUNT);

        // Create multi-shard repository
        List<DataSourceConfig> dataSources = new ArrayList<>();
        for (String dbName : testDatabases) {
            dataSources.add(DataSourceConfig.create("127.0.0.1", 3306, dbName, "root", "123456"));
        }

        multiShardRepo = SplitVerseRepository.<OrderEntity, LocalDateTime>builder()
            .withEntityClass(OrderEntity.class)
            .withTableName("orders")
            .withShardingStrategy(ShardingStrategy.DUAL_KEY_HASH_RANGE)
            .withPartitionColumn("created_at", PartitionColumnType.LOCAL_DATE_TIME)
            .withPartitionRange(PartitionRange.DAILY)
            .withRepositoryMode(RepositoryMode.MULTI_TABLE)
            .withDataSources(dataSources)
            .build();

        System.out.println("Created multi-shard repository with " + SHARD_COUNT + " shards");
    }

    @AfterAll
    public static void cleanup() {
        if (multiShardRepo != null) {
            multiShardRepo.shutdown();
        }
        TestDatabaseSetup.cleanupTestDatabases();
    }

    @Test
    @Order(1)
    public void testDataDistributionAcrossShards() throws SQLException {
        // Insert many orders to verify distribution
        int ordersPerShard = 100;
        int totalOrders = ordersPerShard * SHARD_COUNT;
        List<OrderEntity> orders = new ArrayList<>();

        for (int i = 0; i < totalOrders; i++) {
            OrderEntity order = createOrder("DIST_" + i);
            orders.add(order);
        }

        // Insert all orders
        multiShardRepo.insertMultiple(orders);

        // Track which shard each ID went to (simplified verification)
        Map<Integer, Integer> shardDistribution = new HashMap<>();
        for (OrderEntity order : orders) {
            // Hash the ID to determine shard (simplified)
            int shardIndex = Math.abs(order.getId().hashCode()) % SHARD_COUNT;
            shardDistribution.merge(shardIndex, 1, Integer::sum);
        }

        // Verify distribution is relatively even (allowing 30% variance)
        int expectedPerShard = totalOrders / SHARD_COUNT;
        int minAcceptable = (int)(expectedPerShard * 0.7);
        int maxAcceptable = (int)(expectedPerShard * 1.3);

        for (int count : shardDistribution.values()) {
            assertTrue(count >= minAcceptable && count <= maxAcceptable,
                "Shard distribution should be relatively even. Got: " + count +
                ", Expected: " + expectedPerShard + " ±30%");
        }

        System.out.println("✓ Data distribution test passed. Distribution: " + shardDistribution);
    }

    @Test
    @Order(2)
    public void testConcurrentOperationsAcrossShards() throws Exception {
        int threadCount = 10;
        int operationsPerThread = 50;
        ExecutorService executor = Executors.newFixedThreadPool(threadCount);
        List<Future<Integer>> futures = new ArrayList<>();

        // Submit concurrent operations
        for (int t = 0; t < threadCount; t++) {
            final int threadId = t;
            futures.add(executor.submit(() -> {
                int successCount = 0;
                for (int i = 0; i < operationsPerThread; i++) {
                    try {
                        OrderEntity order = createOrder("CONCURRENT_T" + threadId + "_" + i);
                        multiShardRepo.insert(order);

                        // Verify immediately
                        OrderEntity found = multiShardRepo.findById(order.getId());
                        if (found != null && found.getId().equals(order.getId())) {
                            successCount++;
                        }
                    } catch (SQLException e) {
                        System.err.println("Error in thread " + threadId + ": " + e.getMessage());
                    }
                }
                return successCount;
            }));
        }

        // Wait for completion and verify results
        int totalSuccess = 0;
        for (Future<Integer> future : futures) {
            totalSuccess += future.get(30, TimeUnit.SECONDS);
        }

        executor.shutdown();
        executor.awaitTermination(5, TimeUnit.SECONDS);

        int expectedTotal = threadCount * operationsPerThread;
        assertTrue(totalSuccess >= expectedTotal * 0.95,
            "At least 95% of concurrent operations should succeed. Got: " +
            totalSuccess + "/" + expectedTotal);

        System.out.println("✓ Concurrent operations test passed with " +
            totalSuccess + "/" + expectedTotal + " successful operations");
    }

    @Test
    @Order(3)
    public void testCrossShardQueries() throws SQLException {
        // Insert orders across different dates (partitions) and shards
        LocalDateTime baseTime = LocalDateTime.now();
        List<OrderEntity> orders = new ArrayList<>();
        Map<LocalDateTime, List<String>> idsByDate = new HashMap<>();

        for (int day = -2; day <= 2; day++) {
            LocalDateTime date = baseTime.plusDays(day);
            List<String> dayIds = new ArrayList<>();

            for (int i = 0; i < 20; i++) {
                OrderEntity order = createOrder("XSHARD_D" + day + "_" + i);
                order.setCreatedAt(date);
                orders.add(order);
                dayIds.add(order.getId());
            }

            idsByDate.put(date, dayIds);
        }

        // Insert all orders
        multiShardRepo.insertMultiple(orders);

        // Test date range query across all shards
        List<OrderEntity> foundOrders = multiShardRepo.findAllByDateRange(
            baseTime.minusDays(3),
            baseTime.plusDays(3)
        );

        assertTrue(foundOrders.size() >= orders.size() * 0.9,
            "Should find at least 90% of orders in date range query");

        // Test specific date queries
        for (Map.Entry<LocalDateTime, List<String>> entry : idsByDate.entrySet()) {
            LocalDateTime date = entry.getKey();
            List<OrderEntity> dayOrders = multiShardRepo.findAllByDateRange(
                date.withHour(0).withMinute(0),
                date.withHour(23).withMinute(59)
            );

            assertTrue(dayOrders.size() >= entry.getValue().size() * 0.8,
                "Should find most orders for specific day");
        }

        System.out.println("✓ Cross-shard query test passed with " +
            foundOrders.size() + " orders found");
    }

    @Test
    @Order(4)
    public void testShardFailoverBehavior() throws SQLException {
        // This test verifies behavior when one shard is slow/unavailable
        // In real scenario, we'd simulate shard failure
        // For now, we test that operations continue even with errors

        List<OrderEntity> orders = new ArrayList<>();
        for (int i = 0; i < 30; i++) {
            orders.add(createOrder("FAILOVER_" + i));
        }

        // Insert orders - should work even if some operations fail
        try {
            multiShardRepo.insertMultiple(orders);
        } catch (Exception e) {
            // Some operations might fail, but not all
            System.out.println("Partial failure as expected: " + e.getMessage());
        }

        // Verify we can still query
        int foundCount = 0;
        for (OrderEntity order : orders) {
            try {
                OrderEntity found = multiShardRepo.findById(order.getId());
                if (found != null) foundCount++;
            } catch (SQLException e) {
                // Individual query might fail
            }
        }

        assertTrue(foundCount > 0, "Should be able to find some orders despite failures");
        System.out.println("✓ Shard failover test passed with " +
            foundCount + "/" + orders.size() + " orders accessible");
    }

    @Test
    @Order(5)
    public void testBatchOperationsAcrossMultipleShards() throws SQLException {
        // Create a large batch spanning multiple shards
        List<OrderEntity> batch = new ArrayList<>();
        for (int i = 0; i < 300; i++) {
            batch.add(createOrder("BATCH_MS_" + i));
        }

        // Batch insert
        long startTime = System.currentTimeMillis();
        multiShardRepo.insertMultiple(batch);
        long insertTime = System.currentTimeMillis() - startTime;

        // Verify all inserted
        List<String> batchIds = batch.stream()
            .map(OrderEntity::getId)
            .toList();

        List<OrderEntity> found = multiShardRepo.findAllByIdsAndDateRange(
            batchIds,
            LocalDateTime.now().minusHours(1),
            LocalDateTime.now().plusHours(1)
        );

        assertTrue(found.size() >= batch.size() * 0.9,
            "Should find at least 90% of batch inserted orders");

        System.out.println("✓ Multi-shard batch test passed. " +
            "Inserted " + batch.size() + " orders in " + insertTime + "ms");
    }

    @Test
    @Order(6)
    public void testPaginationAcrossShards() throws SQLException {
        // Insert ordered data
        List<String> allIds = new ArrayList<>();
        for (int i = 0; i < 150; i++) {
            OrderEntity order = createOrder("PAGE_" + String.format("%03d", i));
            multiShardRepo.insert(order);
            allIds.add(order.getId());
        }

        // Test pagination across shards
        Set<String> paginatedIds = new HashSet<>();
        String cursor = "";
        int pageSize = 25;
        int pageCount = 0;

        while (pageCount < 10) { // Safety limit
            List<OrderEntity> page = multiShardRepo.findBatchByIdGreaterThan(cursor, pageSize);
            if (page.isEmpty()) break;

            for (OrderEntity order : page) {
                paginatedIds.add(order.getId());
            }

            cursor = page.get(page.size() - 1).getId();
            pageCount++;
        }

        // Verify we retrieved a good portion of data via pagination
        assertTrue(paginatedIds.size() >= 100,
            "Should retrieve at least 100 orders via pagination across shards");

        System.out.println("✓ Multi-shard pagination test passed with " +
            paginatedIds.size() + " unique orders retrieved in " + pageCount + " pages");
    }

    private OrderEntity createOrder(String prefix) {
        OrderEntity order = new OrderEntity();
        order.setId(prefix + "_" + UUID.randomUUID().toString().replace("-", "").substring(0, 10));
        order.setCreatedAt(LocalDateTime.now());
        order.setCustomerId("CUST_" + (int)(Math.random() * 1000));
        order.setAmount(Math.random() * 10000);
        order.setStatus("PENDING");
        return order;
    }
}