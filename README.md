# Split-Verse: Production-Ready Sharding & Partitioning Framework for MySQL

**Split-Verse** is a high-performance Java framework for transparent data sharding and partitioning in MySQL. It provides automatic partition management, seamless CRUD operations across sharded tables, and built-in support for time-series data with high-performance sequential ID management.

## üéØ Key Features

### Core Capabilities
- **Transparent Sharding**: Automatic routing to correct partitions based on sharding keys
- **Multiple Repository Types**:
  - **GenericPartitionedTableRepository**: Single partitioned table with auto-management
  - **GenericMultiTableRepository**: Multiple tables with consistent sharding
  - **SimpleSequentialRepository**: Sequential numeric IDs with state persistence
  - **Multi-Entity Repository**: Single repository managing multiple entity types (Work in Progress)
- **Flexible ID Strategies**:
  - String IDs (UUID, ULID, NanoID) for distributed systems
  - Sequential numeric IDs for Chronicle-like messaging systems
  - Client-provided IDs with automatic sequence advancement
- **Automatic Partition Management**: Creates, maintains, and drops partitions automatically
- **Manual Partition Mode**: Option to disable automatic management for pre-existing tables
- **Zero-Downtime Operations**: All partition operations are online
- **Builder-Only API**: Type-safe configuration with compile-time validation
- **Connection Pooling**: Built-in HikariCP integration for optimal performance
- **Thread-Safe**: All operations are thread-safe for concurrent access
- **Batch Operations**: Efficient bulk insert/update/delete operations
- **Simple Batch Retrieval**: Direct ID range queries without cursor complexity
- **Type-Safe Query DSL**: Fluent API for building complex queries
- **Cross-Database Support**: MySQL, PostgreSQL, Oracle, SQL Server
- **Monitoring & Metrics**: Built-in performance monitoring and metrics collection

### Advanced Features
- **Partition Boundary Management**: Intelligent handling of data outside partition ranges
- **Automatic Query Optimization**: Query parameter adjustment for partition pruning
- **Metadata Consistency**: Strict validation of partition boundaries
- **Cross-Shard Pagination**: Seamless pagination across multiple shards
- **Connection Management**: Automatic connection pooling and lifecycle management
- **SQL Caching**: Prepared statement caching for improved performance
- **Monitoring Dashboard**: HTTP metrics endpoint for real-time monitoring

## üìã Table of Contents
- [Quick Start](#-quick-start)
- [Repository Types](#-repository-types)
- [Configuration Options](#-configuration-options)
- [API Reference](#-api-reference)
- [Query DSL](#-query-dsl)
- [Architecture](#-architecture)
- [Advanced Usage](#-advanced-usage)
- [Performance Tuning](#-performance-tuning)
- [Testing](#-testing)
- [Examples](#-examples)

## üöÄ Quick Start

### 1. Define Your Entity

```java
@Table(name = "events")
public class Event implements ShardingEntity<LocalDateTime> {

    @Id(autoGenerated = false)  // Required: external ID generation
    @Column(name = "id")
    private String id;

    @ShardingKey  // Required: LocalDateTime for partitioning
    @Column(name = "created_at")
    private LocalDateTime createdAt;

    @Column(name = "event_type")
    private String eventType;

    @Column(name = "payload")
    private String payload;

    // Required interface methods
    @Override
    public String getId() { return id; }

    @Override
    public void setId(String id) { this.id = id; }

    @Override
    public LocalDateTime getPartitionColValue() { return createdAt; }

    @Override
    public void setPartitionColValue(LocalDateTime value) {
        this.createdAt = value;
    }
}
```

### 2. Choose Your Repository Type

```java
// Option 1: GenericPartitionedTableRepository - Single table with partitions
GenericPartitionedTableRepository<Event> partitionedRepo =
    GenericPartitionedTableRepository.builder(Event.class)
        .connection("127.0.0.1", 3306, "mydb", "user", "pass")
        .tableName("events")
        .partitionRange(PartitionRange.DAILY)
        .retentionDays(30)
        .autoManagePartitions(true)  // Enable automatic management (default)
        .build();

// Option 2: GenericMultiTableRepository - Multiple tables
GenericMultiTableRepository<Event> multiTableRepo =
    GenericMultiTableRepository.builder(Event.class)
        .connection("127.0.0.1", 3306, "mydb", "user", "pass")
        .tablePrefix("events")
        .shardingStrategy(ShardingStrategy.MONTHLY)
        .retentionMonths(6)
        .autoManagePartitions(true)  // Enable automatic management (default)
        .build();

// Option 3: SimpleSequentialRepository - Sequential IDs
SimpleSequentialRepository<LogEntry> seqRepo =
    SimpleSequentialRepository.builder(LogEntry.class)
        .connection("127.0.0.1", 3306, "mydb", "user", "pass")
        .tableName("logs")
        .maxId(1000000)
        .allowClientIds(true)  // Accept external sequential IDs
        .build();
```

## üìö Repository Types

### GenericPartitionedTableRepository

Single table with MySQL native range partitions. Best for standard time-series data.

**Features:**
- Native MySQL partitioning (RANGE BY)
- Automatic partition creation/deletion
- Optimized for queries within partition boundaries
- Supports DAILY, MONTHLY, YEARLY partition ranges
- Optional manual management mode

**Use Cases:**
- Log data with daily/monthly retention
- Time-series metrics
- Event streaming

```java
GenericPartitionedTableRepository<Event> repo =
    GenericPartitionedTableRepository.builder(Event.class)
        .connection(config)
        .tableName("events")
        .partitionRange(PartitionRange.DAILY)
        .retentionDays(30)
        .autoManagePartitions(false)  // Manual mode - assumes tables exist
        .build();
```

### GenericMultiTableRepository

Multiple tables with consistent naming pattern. Best for high-volume time-series data.

**Features:**
- Table per time period (hour/day/month)
- Automatic table creation/deletion
- Parallel operations across tables
- Optimized for write-heavy workloads
- Optional manual management mode

**Use Cases:**
- High-frequency sensor data
- CDR (Call Detail Records)
- IoT telemetry

```java
GenericMultiTableRepository<SmsRecord> repo =
    GenericMultiTableRepository.builder(SmsRecord.class)
        .connection(config)
        .tablePrefix("sms")
        .shardingStrategy(ShardingStrategy.HOURLY)
        .retentionHours(24)
        .autoManagePartitions(false)  // Manual mode - assumes tables exist
        .build();
```

### SimpleSequentialRepository

Optimized for sequential numeric IDs with state persistence.

**Features:**
- Sequential ID generation
- State persistence across restarts
- Client ID acceptance with validation
- Automatic ID advancement
- Batch operations optimized for sequential access

**Use Cases:**
- Message queues (Chronicle-like)
- Audit logs
- Transaction logs

```java
SimpleSequentialRepository<LogEntry> repo =
    SimpleSequentialRepository.builder(LogEntry.class)
        .connection(config)
        .tableName("logs")
        .maxId(10_000_000)
        .stateFile("/var/lib/app/seq_state.dat")
        .allowClientIds(true)
        .build();
```

## ‚öôÔ∏è Configuration Options

### Common Builder Options

| Option | Description | Default | Applies To |
|--------|-------------|---------|------------|
| `connection()` | Database connection details | Required | All |
| `tableName()` / `tablePrefix()` | Table naming | Required | All |
| `maxConnectionPoolSize()` | HikariCP pool size | 10 | All |
| `connectionTimeout()` | Connection timeout (ms) | 30000 | All |
| `autoManagePartitions()` | Enable automatic partition management | true | Partitioned/Multi-table |
| `initializeOnStart()` | Create tables/partitions at startup | true | Partitioned/Multi-table |
| `enableMonitoring()` | Enable metrics collection | false | All |
| `monitoringPort()` | HTTP metrics port | 9090 | All |

### Repository-Specific Options

#### GenericPartitionedTableRepository
- `partitionRange()`: DAILY, MONTHLY, YEARLY
- `retentionDays()` / `retentionMonths()`: Data retention period
- `futurePartitions()`: Number of future partitions to maintain (default: 3)

#### GenericMultiTableRepository
- `shardingStrategy()`: HOURLY, DAILY, MONTHLY
- `retentionHours()` / `retentionDays()` / `retentionMonths()`: Data retention

#### SimpleSequentialRepository
- `maxId()`: Maximum ID value before wrapping
- `stateFile()`: Path to persist current ID state
- `allowClientIds()`: Accept externally provided sequential IDs

## üìñ API Reference

### Core Operations

All repositories implement these core operations:

```java
// Single entity operations
void save(T entity);
Optional<T> findById(String id);
boolean exists(String id);
void delete(String id);
void update(T entity);

// Batch operations
int[] saveBatch(List<T> entities);
List<T> findAllByIds(List<String> ids);
void deleteBatch(List<String> ids);

// Range queries (for partitioned repositories)
List<T> findByPartitionRange(LocalDateTime start, LocalDateTime end);
List<T> findByPartitionRange(LocalDateTime start, LocalDateTime end, int limit);

// ID + partition range queries (optimized)
Optional<T> findByIdAndPartitionColRange(String id, LocalDateTime start, LocalDateTime end);

// Count operations
long count();
long countByPartitionRange(LocalDateTime start, LocalDateTime end);
```

### Sequential Repository Additional Methods

```java
// Sequential-specific operations
List<T> findByIdRange(long startId, long endId);
long getCurrentId();
void resetIdSequence();
```

### Multi-Entity Repository (Work in Progress)

```java
// Multi-entity builder pattern
MultiEntityRepository repo = MultiEntityRepository.builder()
    .registerEntity(User.class)
        .tableName("users")
        .partitionRange(PartitionRange.MONTHLY)
        .retentionMonths(12)
        .autoManagePartitions(false)  // Manual mode
        .done()
    .registerEntity(Order.class)
        .tableName("orders")
        .partitionRange(PartitionRange.DAILY)
        .retentionDays(90)
        .done()
    .connection(config)
    .build();

// Usage
repo.save(user);
repo.save(order);
Optional<User> user = repo.findById(User.class, userId);
```

## üîç Query DSL

Type-safe, fluent API for building complex queries:

### Basic Queries

```java
// Simple select with conditions
String query = QueryDSL.select()
    .column("user_id")
    .column("created_at")
    .from("events")
    .where("event_type").eq("LOGIN")
    .and("created_at").gte(LocalDateTime.now().minusDays(7))
    .orderBy("created_at", DESC)
    .limit(100)
    .build();

// Aggregation query
String query = QueryDSL.select()
    .column("event_type")
    .count("event_count")
    .from("events")
    .where("created_at").between(startDate, endDate)
    .groupBy("event_type")
    .having("event_count").gt(100)
    .build();
```

### Advanced Queries

```java
// Complex conditions with OR
String query = QueryDSL.select()
    .all()
    .from("users")
    .where(
        QueryDSL.condition("status").eq("ACTIVE")
            .and("created_at").gte(cutoffDate)
    )
    .or(
        QueryDSL.condition("role").eq("ADMIN")
    )
    .build();

// Subqueries
String query = QueryDSL.select()
    .column("order_id")
    .column("total")
    .from("orders")
    .where("user_id").in(
        QueryDSL.select()
            .column("user_id")
            .from("premium_users")
            .where("subscription_end").gte(LocalDateTime.now())
    )
    .build();
```

### Integration with Repositories

```java
// Custom queries with repositories
List<Event> results = repository.executeQuery(
    QueryDSL.select()
        .all()
        .from("@table")  // @table placeholder for dynamic table names
        .where("event_type").eq("ERROR")
        .and("@partition_col").between(start, end)  // @partition_col for partition column
        .orderBy("created_at", DESC)
        .limit(1000)
);
```

## üèóÔ∏è Architecture

### Core Components

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Application Layer               ‚îÇ
‚îÇ     (User Entities & DAOs)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Repository Layer                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ GenericPartitionedTableRepo  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ GenericMultiTableRepository  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ SimpleSequentialRepository   ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     SQL Generation Layer            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ SqlGenerator (per DB type)   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ QueryDSL                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ PreparedStatement Cache      ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Connection Layer                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ HikariCP Connection Pool     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Connection Provider          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Transaction Management       ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Database Layer                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ MySQL with Partitions        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ PostgreSQL / Oracle / MSSQL  ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Key Design Principles

1. **Entity-Centric Design**
   - All entities implement `ShardingEntity<P>` interface
   - Metadata-driven operations via reflection (cached)
   - Type-safe operations throughout

2. **Builder Pattern**
   - All repositories created via builders
   - Compile-time validation of configuration
   - Immutable configuration after build

3. **Performance Optimizations**
   - Connection pooling with HikariCP
   - PreparedStatement caching
   - Batch operations
   - Partition pruning via query optimization

4. **Fail-Fast Behavior**
   - Early validation of configuration
   - Clear error messages
   - Automatic rollback on failures

## üöÄ Advanced Usage

### Manual Partition Management

When you have pre-existing tables/partitions and don't want automatic management:

```java
// Disable automatic partition management
GenericPartitionedTableRepository<Event> repo =
    GenericPartitionedTableRepository.builder(Event.class)
        .connection(config)
        .tableName("events")
        .partitionRange(PartitionRange.DAILY)
        .autoManagePartitions(false)  // Disable auto-management
        .build();

// Repository will:
// - NOT create tables/partitions at startup
// - NOT enforce retention periods
// - NOT perform maintenance operations
// - Fail fast if tables don't exist
```

### Custom ID Strategies

```java
// Using ULID for distributed systems
public class Event implements ShardingEntity<LocalDateTime> {
    @Id(autoGenerated = false)
    private String id = ULID.random();
    // ...
}

// Using NanoID for shorter IDs
public class Event implements ShardingEntity<LocalDateTime> {
    @Id(autoGenerated = false)
    private String id = NanoIdUtils.randomNanoId();
    // ...
}
```

### Monitoring and Metrics

```java
// Enable monitoring
GenericMultiTableRepository<Event> repo =
    GenericMultiTableRepository.builder(Event.class)
        .connection(config)
        .enableMonitoring(true)
        .monitoringPort(9090)
        .build();

// Access metrics at http://localhost:9090/metrics
// Returns JSON with:
// - Operation counts and latencies
// - Connection pool stats
// - Partition information
// - Error rates
```

### Cross-Shard Operations

```java
// Configure multiple shards
SplitVerseRepository<User> repository = SplitVerseRepository.builder(User.class)
    .addShard(shard1Config)
    .addShard(shard2Config)
    .shardingStrategy(HashShardingStrategy.class)
    .build();

// Automatic routing based on sharding key
repository.save(user);  // Routes to correct shard

// Cross-shard queries
List<User> users = repository.findAll()
    .where("status").eq("ACTIVE")
    .acrossAllShards()
    .execute();
```

### Transaction Management

```java
// Manual transaction control
Connection conn = repository.getConnection();
try {
    conn.setAutoCommit(false);

    repository.save(entity1);
    repository.save(entity2);
    repository.update(entity3);

    conn.commit();
} catch (Exception e) {
    conn.rollback();
    throw e;
} finally {
    conn.setAutoCommit(true);
    conn.close();
}
```

## ‚ö° Performance Tuning

### Connection Pool Tuning

```java
.maxConnectionPoolSize(20)        // Increase for high concurrency
.connectionTimeout(10000)         // Reduce for faster failure detection
.idleTimeout(600000)             // 10 minutes idle timeout
.maxLifetime(1800000)            // 30 minutes max connection lifetime
```

### Batch Size Optimization

```java
// Optimal batch sizes depend on data size
int BATCH_SIZE = 1000;  // Good default for most cases

List<Event> events = generateEvents(10000);
for (int i = 0; i < events.size(); i += BATCH_SIZE) {
    List<Event> batch = events.subList(i,
        Math.min(i + BATCH_SIZE, events.size()));
    repository.saveBatch(batch);
}
```

### Query Optimization

```java
// Always include partition column in WHERE clause for partition pruning
repository.findByIdAndPartitionColRange(id, startDate, endDate);
// This is much faster than:
repository.findById(id);  // Scans all partitions
```

### Memory Management

```java
// Use streaming for large result sets
try (Stream<Event> events = repository.stream()
    .where("created_at").between(start, end)
    .execute()) {

    events.forEach(event -> {
        // Process one at a time
        processEvent(event);
    });
}
```

## üß™ Testing

### Unit Testing

```java
@Test
public void testPartitionedRepository() {
    // Create test repository
    GenericPartitionedTableRepository<TestEntity> repo =
        GenericPartitionedTableRepository.builder(TestEntity.class)
            .connection("localhost", 3306, "test_db", "user", "pass")
            .tableName("test_events")
            .partitionRange(PartitionRange.DAILY)
            .retentionDays(7)
            .build();

    // Test operations
    TestEntity entity = new TestEntity();
    entity.setId(UUID.randomUUID().toString());
    entity.setCreatedAt(LocalDateTime.now());

    repo.save(entity);

    Optional<TestEntity> retrieved = repo.findById(entity.getId());
    assertTrue(retrieved.isPresent());
    assertEquals(entity.getId(), retrieved.get().getId());
}
```

### Integration Testing

```java
@Test
public void testAutoManagePartitionsDisabled() {
    // Pre-create table
    createTableManually("test_table");

    // Create repository with auto-management disabled
    GenericPartitionedTableRepository<TestEntity> repo =
        GenericPartitionedTableRepository.builder(TestEntity.class)
            .connection(testConfig)
            .tableName("test_table")
            .autoManagePartitions(false)  // Disable auto-management
            .build();

    // Verify it uses existing table
    TestEntity entity = createTestEntity();
    repo.save(entity);

    // Verify no new partitions created
    assertEquals(1, countTablesInDatabase());
}

@Test(expected = SQLException.class)
public void testAutoManagePartitionsDisabledNoTable() {
    // Try to create repository without existing table
    GenericPartitionedTableRepository<TestEntity> repo =
        GenericPartitionedTableRepository.builder(TestEntity.class)
            .connection(testConfig)
            .tableName("non_existent_table")
            .autoManagePartitions(false)
            .build();  // Should throw SQLException
}
```

### Performance Testing

```java
@Test
public void testHighThroughputInsert() {
    GenericMultiTableRepository<Event> repo = createRepository();

    int numThreads = 10;
    int eventsPerThread = 10000;
    ExecutorService executor = Executors.newFixedThreadPool(numThreads);

    long startTime = System.currentTimeMillis();

    List<Future<?>> futures = new ArrayList<>();
    for (int i = 0; i < numThreads; i++) {
        futures.add(executor.submit(() -> {
            List<Event> events = generateEvents(eventsPerThread);
            repo.saveBatch(events);
        }));
    }

    // Wait for completion
    futures.forEach(f -> {
        try { f.get(); } catch (Exception e) { fail(e.getMessage()); }
    });

    long duration = System.currentTimeMillis() - startTime;
    long totalEvents = numThreads * eventsPerThread;
    double throughput = totalEvents / (duration / 1000.0);

    System.out.println("Throughput: " + throughput + " events/sec");
    assertTrue(throughput > 10000);  // Expect > 10k events/sec
}
```

## üìÇ Examples

### Complete SMS Processing System

```java
// Entity definition
@Table(name = "sms_records")
public class SmsRecord implements ShardingEntity<LocalDateTime> {
    @Id
    private String messageId;

    @ShardingKey
    @Column(name = "sent_at")
    private LocalDateTime sentAt;

    @Column(name = "sender")
    private String sender;

    @Column(name = "recipient")
    private String recipient;

    @Column(name = "message")
    private String message;

    @Column(name = "status")
    private String status;

    // Getters/setters...
}

// Repository setup
public class SmsRepository {
    private final GenericMultiTableRepository<SmsRecord> repository;

    public SmsRepository(DatabaseConfig config) {
        this.repository = GenericMultiTableRepository.builder(SmsRecord.class)
            .connection(config.getHost(), config.getPort(),
                       config.getDatabase(), config.getUser(),
                       config.getPassword())
            .tablePrefix("sms")
            .shardingStrategy(ShardingStrategy.HOURLY)
            .retentionHours(168)  // 7 days
            .maxConnectionPoolSize(20)
            .enableMonitoring(true)
            .monitoringPort(9090)
            .build();
    }

    public void processSms(SmsRecord sms) {
        // Save to appropriate hourly table
        repository.save(sms);
    }

    public List<SmsRecord> getRecentMessages(String phoneNumber, int hours) {
        LocalDateTime start = LocalDateTime.now().minusHours(hours);
        LocalDateTime end = LocalDateTime.now();

        return repository.executeQuery(
            QueryDSL.select()
                .all()
                .from("@table")
                .where("sender").eq(phoneNumber)
                .or("recipient").eq(phoneNumber)
                .and("@partition_col").between(start, end)
                .orderBy("sent_at", DESC)
                .build()
        );
    }

    public Map<String, Long> getHourlyStats(LocalDateTime date) {
        // Get stats for a specific day
        LocalDateTime dayStart = date.truncatedTo(ChronoUnit.DAYS);
        LocalDateTime dayEnd = dayStart.plusDays(1);

        List<Map<String, Object>> results = repository.executeQuery(
            QueryDSL.select()
                .function("DATE_FORMAT(sent_at, '%Y-%m-%d %H:00:00')", "hour")
                .count("message_count")
                .from("@table")
                .where("@partition_col").between(dayStart, dayEnd)
                .groupBy("hour")
                .build()
        );

        return results.stream()
            .collect(Collectors.toMap(
                r -> (String) r.get("hour"),
                r -> (Long) r.get("message_count")
            ));
    }
}
```

### Event Sourcing System

```java
// Event entity
@Table(name = "domain_events")
public class DomainEvent implements ShardingEntity<LocalDateTime> {
    @Id
    private String eventId;

    @ShardingKey
    @Column(name = "occurred_at")
    private LocalDateTime occurredAt;

    @Column(name = "aggregate_id")
    private String aggregateId;

    @Column(name = "event_type")
    private String eventType;

    @Column(name = "event_data")
    private String eventData;  // JSON

    @Column(name = "user_id")
    private String userId;

    // Getters/setters...
}

// Event store implementation
public class EventStore {
    private final GenericPartitionedTableRepository<DomainEvent> repository;

    public EventStore(DatabaseConfig config) {
        this.repository = GenericPartitionedTableRepository.builder(DomainEvent.class)
            .connection(config)
            .tableName("domain_events")
            .partitionRange(PartitionRange.MONTHLY)
            .retentionMonths(24)  // 2 years
            .futurePartitions(3)   // Create 3 months ahead
            .build();
    }

    public void append(DomainEvent event) {
        event.setEventId(ULID.random());
        event.setOccurredAt(LocalDateTime.now());
        repository.save(event);
    }

    public List<DomainEvent> getAggregateHistory(String aggregateId) {
        return repository.executeQuery(
            QueryDSL.select()
                .all()
                .from("@table")
                .where("aggregate_id").eq(aggregateId)
                .orderBy("occurred_at", ASC)
                .build()
        );
    }

    public List<DomainEvent> getEventsSince(LocalDateTime since) {
        return repository.findByPartitionRange(since, LocalDateTime.now());
    }

    public void replayEvents(LocalDateTime from, LocalDateTime to,
                            Consumer<DomainEvent> handler) {
        int batchSize = 1000;
        LocalDateTime current = from;

        while (current.isBefore(to)) {
            List<DomainEvent> events = repository.executeQuery(
                QueryDSL.select()
                    .all()
                    .from("@table")
                    .where("@partition_col").gte(current)
                    .and("@partition_col").lt(to)
                    .orderBy("occurred_at", ASC)
                    .limit(batchSize)
                    .build()
            );

            if (events.isEmpty()) break;

            events.forEach(handler);
            current = events.get(events.size() - 1).getOccurredAt();
        }
    }
}
```

## üîß Troubleshooting

### Common Issues

1. **Table doesn't exist with autoManagePartitions=false**
   - Ensure tables are created manually before repository initialization
   - Check table naming matches configuration

2. **Partition pruning not working**
   - Always include partition column in WHERE clause
   - Use `findByIdAndPartitionColRange()` instead of `findById()`

3. **Connection pool exhaustion**
   - Increase `maxConnectionPoolSize`
   - Check for connection leaks
   - Monitor with metrics endpoint

4. **High memory usage**
   - Use batch operations with reasonable batch sizes
   - Stream large result sets instead of loading all
   - Tune JVM heap settings

## üìù License

This project is licensed under the MIT License - see the LICENSE file for details.

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## üìû Support

For issues, questions, or suggestions, please open an issue on GitHub.