# Split-Verse: Sharding-Aware Repository Framework

**Split-Verse** is a production-ready Java framework for transparent data sharding and partitioning in MySQL. It provides automatic partition management, seamless CRUD operations across sharded tables, and built-in support for time-series data with high-performance sequential ID management.

## 🎯 Key Features

- **Transparent Sharding**: Automatic routing to correct partitions based on sharding keys
- **Multiple Repository Types**:
  - **GenericPartitionedTableRepository**: Single partitioned table with auto-management
  - **GenericMultiTableRepository**: Multiple tables with consistent sharding
  - **SimpleSequentialRepository**: Sequential numeric IDs with state persistence
- **Flexible ID Strategies**:
  - String IDs (UUID, ULID, NanoID) for distributed systems
  - Sequential numeric IDs for Chronicle-like messaging systems
  - Client-provided IDs with automatic sequence advancement
- **Automatic Partition Management**: Creates, maintains, and drops partitions automatically
- **Zero-Downtime Operations**: All partition operations are online
- **Builder-Only API**: Type-safe configuration with compile-time validation
- **Connection Pooling**: Built-in HikariCP integration for optimal performance
- **Thread-Safe**: All operations are thread-safe for concurrent access
- **Batch Operations**: Efficient bulk insert/update/delete operations
- **Simple Batch Retrieval**: Direct ID range queries without cursor complexity

## 🚀 Quick Start

### 1. Define Your Entity

```java
@Table(name = "events")
public class Event implements ShardingEntity<LocalDateTime> {

    @Id(autoGenerated = false)  // Required: external ID generation
    @Column(name = "id")
    private String id;

    @ShardingKey  // Required: LocalDateTime for partitioning
    @Column(name = "created_at")
    private LocalDateTime createdAt;

    @Column(name = "event_type")
    private String eventType;

    @Column(name = "payload")
    private String payload;

    // Required interface methods
    @Override
    public String getId() { return id; }

    @Override
    public void setId(String id) { this.id = id; }

    @Override
    public LocalDateTime getPartitionColValue() { return createdAt; }

    @Override
    public void setPartitionColValue(LocalDateTime value) {
        this.createdAt = value;
    }
}
```

### 2. Choose Your Repository Type

```java
// Option 1: GenericPartitionedTableRepository - Single table with partitions
GenericPartitionedTableRepository<Event> partitionedRepo =
    GenericPartitionedTableRepository.builder(Event.class)
        .connection("127.0.0.1", 3306, "mydb", "user", "pass")
        .tableName("events")
        .partitionRange(PartitionRange.DAILY)
        .retentionDays(30)
        .build();

// Option 2: GenericMultiTableRepository - Multiple tables
GenericMultiTableRepository<Event> multiTableRepo =
    GenericMultiTableRepository.builder(Event.class)
        .connection("127.0.0.1", 3306, "mydb", "user", "pass")
        .tablePrefix("events")
        .shardingStrategy(ShardingStrategy.MONTHLY)
        .retentionMonths(6)
        .build();

// Option 3: SimpleSequentialRepository - Sequential IDs
SimpleSequentialRepository<LogEntry> seqRepo =
    SimpleSequentialRepository.builder(LogEntry.class)
        .connection("127.0.0.1", 3306, "mydb", "user", "pass")
        .tableName("logs")
        .maxId(1000000)
        .allowClientIds(true)  // Accept external sequential IDs
        .build();
```

## 📚 Repository Types

### GenericPartitionedTableRepository

Single table with MySQL native range partitions. Best for standard time-series data.

**Features:**
- RANGE COLUMNS partitioning for date-based data
- All partitions created upfront during initialization
- Automatic partition maintenance (add/drop)
- Efficient partition pruning for date queries

**Configuration:**
```java
GenericPartitionedTableRepository<Event> repository =
    GenericPartitionedTableRepository.builder(Event.class)
        .connection("127.0.0.1", 3306, "mydb", "user", "pass")
        .tableName("events")
        .partitionRange(PartitionRange.DAILY)  // DAILY, MONTHLY, YEARLY
        .retentionDays(30)  // Keep 30 days of data
        .autoMaintenance(true)  // Auto-manage partitions
        .maintenanceTime(LocalTime.of(4, 0))  // Run at 4 AM
        .maxPoolSize(20)  // Connection pool size
        .build();
```

### GenericMultiTableRepository

Multiple tables with time-based or value-based sharding. Best for complete data isolation.

**Features:**
- Separate table for each time period or value range
- Dynamic table creation and management
- Easy archival (simple DROP TABLE)
- Flexible retention policies

**Configuration:**
```java
GenericMultiTableRepository<Event> repository =
    GenericMultiTableRepository.builder(Event.class)
        .connection("127.0.0.1", 3306, "mydb", "user", "pass")
        .tablePrefix("events")  // Creates events_20250101, etc.
        .shardingStrategy(ShardingStrategy.DAILY)  // Per-day tables
        .retentionDays(30)
        .createTablesUpfront(true)  // Pre-create all tables
        .autoMaintenance(true)
        .build();
```

### SimpleSequentialRepository

Specialized repository for sequential numeric IDs with state persistence. Perfect for log storage and Chronicle-like messaging systems.

**Features:**
- Sequential ID generation (1, 2, 3, ...)
- State persistence across restarts
- Thread-safe concurrent access
- Client-provided ID support
- Range reservation for distributed systems
- Simple batch retrieval without cursors

**Configuration:**
```java
SimpleSequentialRepository<LogEntry> repository =
    SimpleSequentialRepository.builder(LogEntry.class)
        .connection("127.0.0.1", 3306, "mydb", "user", "pass")
        .tableName("logs")
        .stateTableName("log_id_state")  // State persistence table
        .maxId(10000000)  // Maximum ID value
        .wrapAround(true)  // Wrap to 1 at max
        .allowClientIds(true)  // Accept external IDs
        .retentionDays(90)  // Keep 90 days
        .partitionRange(PartitionRange.DAILY)
        .build();
```

## 🔧 API Reference

### Common Operations (All Repositories)

```java
// Insert operations
void insert(T entity)
void insertMultiple(List<T> entities)

// Find operations
T findById(String id)
List<T> findAll()
List<T> findByPartitionColBetween(LocalDateTime start, LocalDateTime end)

// Update operations
void updateById(String id, T entity)
void updateMultiple(List<T> entities)

// Delete operations
void deleteById(String id)
void deleteByPartitionColBefore(LocalDateTime cutoff)

// Lifecycle
void shutdown()
```

### SimpleSequentialRepository Specific APIs

#### ID Generation
```java
// Get next sequential ID
long nextId = repository.getNextId();  // Returns: 1, 2, 3, ...

// Get multiple IDs at once
List<Long> ids = repository.getNextN(100);  // Returns: [1, 2, ..., 100]

// Check current ID without incrementing
long currentId = repository.getCurrentId();

// Reset ID counter
repository.resetId(1000);  // Next ID will be 1001
```

#### Insertion with Auto-ID
```java
// Single entity with auto-generated ID
LogEntry log = new LogEntry();
log.setTimestamp(LocalDateTime.now());
log.setMessage("Application started");
long assignedId = repository.insertWithAutoId(log);

// Multiple entities with auto-generated IDs
List<LogEntry> logs = createLogs(100);
List<Long> assignedIds = repository.insertMultipleWithAutoId(logs);
```

#### Client-Provided IDs
```java
// Enable in builder
.allowClientIds(true)

// Single entity with client ID
repository.insertWithClientId(log, 5000L);

// Multiple entities with client IDs
List<LogEntry> entities = Arrays.asList(log1, log2, log3);
List<Long> clientIds = Arrays.asList(5001L, 5002L, 5003L);
repository.insertMultipleWithClientIds(entities, clientIds);
```

#### Simple Batch Retrieval
```java
// Retrieve records by ID range - no cursor complexity
// startId=1000, batchSize=100 returns IDs 1000-1099
List<LogEntry> batch = repository.findByIdRange(1000, 100);

// Iterate through all logs sequentially
long currentId = 0;
int batchSize = 1000;

while (true) {
    List<LogEntry> batch = repository.findByIdRange(currentId, batchSize);
    if (batch.isEmpty()) break;

    processBatch(batch);
    currentId += batchSize;
}
```

#### Range Operations
```java
// Reserve a block of IDs for distributed processing
SimpleSequentialRepository.IdRange range = repository.reserveIdRange(1000);
System.out.println("Reserved: " + range.getStartId() + " to " + range.getEndId());

// Insert with reserved range
List<LogEntry> logs = createLogs(1000);
repository.insertWithIdRange(logs, range);

// Insert with specific range (requires allowClientIds)
repository.insertWithinIdRange(logs, 1000L, 1999L);
```

## 📋 Entity Requirements

All entities **MUST** meet these requirements:

| Requirement | Description | Enforcement |
|------------|-------------|-------------|
| **Implements ShardingEntity** | Must implement the interface | Compile-time |
| **Exactly ONE @Id** | Single String ID field | Runtime validation |
| **String ID type** | ID must be String, not Long/Integer | Runtime validation |
| **No AUTO_INCREMENT** | `@Id(autoGenerated = false)` required | Runtime validation |
| **Exactly ONE @ShardingKey** | Single LocalDateTime field for partitioning | Runtime validation |
| **LocalDateTime type** | ShardingKey must be LocalDateTime | Runtime validation |

## 💡 How-To Guides

### How to: Implement High-Performance Log Storage

```java
public class LoggingSystem {
    private final SimpleSequentialRepository<LogEntry> repository;

    public LoggingSystem() {
        this.repository = SimpleSequentialRepository.builder(LogEntry.class)
            .connection("127.0.0.1", 3306, "logs_db", "app", "password")
            .tableName("application_logs")
            .maxId(100000000L)  // 100 million max
            .wrapAround(false)  // Throw error at max
            .retentionDays(90)  // Keep 3 months
            .partitionRange(PartitionRange.DAILY)
            .autoMaintenance(true)
            .build();

        Runtime.getRuntime().addShutdownHook(new Thread(repository::shutdown));
    }

    public void log(String level, String message) throws SQLException {
        LogEntry entry = new LogEntry();
        entry.setTimestamp(LocalDateTime.now());
        entry.setLevel(level);
        entry.setMessage(message);

        long id = repository.insertWithAutoId(entry);
        System.out.printf("Logged with ID %d: [%s] %s%n", id, level, message);
    }

    public void processBatch() {
        long lastProcessedId = loadLastProcessedId();
        int batchSize = 1000;

        while (true) {
            List<LogEntry> batch = repository.findByIdRange(lastProcessedId, batchSize);
            if (batch.isEmpty()) break;

            processBatchData(batch);
            lastProcessedId += batchSize;
            saveLastProcessedId(lastProcessedId);
        }
    }
}
```

### How to: Migrate from External System

```java
public class DataMigration {
    private final SimpleSequentialRepository<LogEntry> repository;

    public DataMigration() {
        this.repository = SimpleSequentialRepository.builder(LogEntry.class)
            .connection(host, port, db, user, pass)
            .tableName("logs_partitioned")
            .allowClientIds(true)  // Accept external IDs
            .build();
    }

    public void migrateFromLegacy(List<LegacyLog> legacyLogs) throws SQLException {
        List<LogEntry> logs = new ArrayList<>();
        List<Long> ids = new ArrayList<>();

        for (LegacyLog legacy : legacyLogs) {
            LogEntry log = convertToLogEntry(legacy);
            logs.add(log);
            ids.add(legacy.getId());
        }

        // Insert preserving original IDs
        repository.insertMultipleWithClientIds(logs, ids);

        // Repository automatically advances counter past highest ID
    }
}
```

### How to: Handle Time-Series Data

```java
public class TimeSeriesService {
    private final GenericPartitionedTableRepository<SensorData> repository;

    public TimeSeriesService() {
        this.repository = GenericPartitionedTableRepository.builder(SensorData.class)
            .connection("127.0.0.1", 3306, "metrics", "user", "pass")
            .tableName("sensor_data")
            .partitionRange(PartitionRange.HOURLY)  // Hourly partitions
            .retentionDays(7)  // Keep 1 week
            .autoMaintenance(true)
            .build();
    }

    public void storeSensorReading(String sensorId, double value) {
        SensorData data = new SensorData();
        data.setId(UUID.randomUUID().toString());
        data.setSensorId(sensorId);
        data.setValue(value);
        data.setTimestamp(LocalDateTime.now());

        repository.insert(data);
    }

    public List<SensorData> getReadingsForPeriod(LocalDateTime start, LocalDateTime end) {
        // Automatically uses partition pruning
        return repository.findByPartitionColBetween(start, end);
    }

    public double getAverageForToday(String sensorId) {
        LocalDateTime today = LocalDate.now().atStartOfDay();
        LocalDateTime tomorrow = today.plusDays(1);

        List<SensorData> todayData = repository.findByPartitionColBetween(today, tomorrow);

        return todayData.stream()
            .filter(d -> d.getSensorId().equals(sensorId))
            .mapToDouble(SensorData::getValue)
            .average()
            .orElse(0.0);
    }
}
```

### How to: Implement Distributed ID Allocation

```java
public class DistributedWorker {
    private final SimpleSequentialRepository<Task> repository;
    private SimpleSequentialRepository.IdRange currentRange;
    private long currentId;

    public void allocateWorkRange() {
        // Each worker reserves a range of 10000 IDs
        currentRange = repository.reserveIdRange(10000);
        currentId = currentRange.getStartId();

        System.out.println("Worker allocated IDs: " +
            currentRange.getStartId() + " - " + currentRange.getEndId());
    }

    public long getNextWorkerId() {
        if (currentId > currentRange.getEndId()) {
            allocateWorkRange();  // Get new range when exhausted
        }
        return currentId++;
    }

    public void processWork() {
        List<Task> tasks = new ArrayList<>();

        // Create tasks with reserved IDs
        for (int i = 0; i < 100; i++) {
            Task task = new Task();
            task.setWorkerId(getNextWorkerId());
            task.setTimestamp(LocalDateTime.now());
            tasks.add(task);
        }

        // Insert with reserved range
        repository.insertWithIdRange(tasks, currentRange);
    }
}
```

### How to: Chronicle Queue-Like Implementation

```java
public class MessageQueue {
    private final SimpleSequentialRepository<Message> repository;
    private long readPosition = 0;

    public MessageQueue() {
        this.repository = SimpleSequentialRepository.builder(Message.class)
            .connection("127.0.0.1", 3306, "queue", "user", "pass")
            .tableName("messages")
            .maxId(Long.MAX_VALUE)
            .allowClientIds(false)  // Auto-generate sequential IDs
            .retentionDays(7)
            .build();
    }

    public long append(String content) throws SQLException {
        Message msg = new Message();
        msg.setContent(content);
        msg.setTimestamp(LocalDateTime.now());

        return repository.insertWithAutoId(msg);
    }

    public List<Message> read(int count) throws SQLException {
        List<Message> messages = repository.findByIdRange(readPosition, count);
        if (!messages.isEmpty()) {
            readPosition += messages.size();
        }
        return messages;
    }

    public void seekTo(long position) {
        this.readPosition = position;
    }

    public long getCurrentPosition() {
        return readPosition;
    }
}
```

## 🏗️ Architecture

### Builder Pattern

Split-Verse enforces a strict builder pattern for all repositories:

```java
// All repositories must be created through builders
GenericPartitionedTableRepository.builder(Entity.class)...
GenericMultiTableRepository.builder(Entity.class)...
SimpleSequentialRepository.builder(Entity.class)...

// Direct instantiation is not allowed (package-private constructors)
```

### Partition Management

#### Partitioned Repository
- Creates all partitions upfront: `(retention_days × 2) + 1`
- Daily maintenance adds future partitions and drops old ones
- Single ALTER TABLE for batch operations

#### Multi-Table Repository
- Creates tables on-demand or upfront
- Each table represents a time period
- Simple DROP TABLE for cleanup

#### Sequential Repository
- Uses underlying partitioned table for data
- Separate state table for ID persistence
- State saved every 100 operations or on shutdown

### Thread Safety

All repositories are thread-safe:
- Connection pooling with HikariCP
- ReentrantLock for ID generation (SimpleSequentialRepository)
- Concurrent read/write operations supported

## 🔍 State Persistence (SimpleSequentialRepository)

The sequential repository maintains state across restarts:

```sql
-- Automatically created state table
CREATE TABLE log_id_state (
    id INT PRIMARY KEY,
    current_id BIGINT NOT NULL,
    max_id BIGINT NOT NULL,
    last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

State is persisted:
- Every 100 ID increments
- On repository shutdown
- When client provides higher ID
- After ID reset

## 📊 Performance Considerations

### Connection Pooling
```java
.maxPoolSize(50)  // Adjust based on load
.connectionTimeout(5000)  // 5 seconds
.maxLifetime(600000)  // 10 minutes
```

### Batch Operations
```java
// Prefer batch operations for better performance
repository.insertMultiple(entities);  // Single transaction
repository.updateMultiple(entities);  // Batch update
repository.deleteMultiple(ids);  // Batch delete
```

### Partition Pruning
```java
// Date queries automatically use partition pruning
repository.findByPartitionColBetween(start, end);
// Only scans relevant partitions
```

### ID Generation Strategy
```java
// For high-throughput sequential IDs
List<Long> ids = repository.getNextN(1000);  // Reserve 1000 IDs at once
// Reduces lock contention
```

## 📝 ID Generation Examples

Since AUTO_INCREMENT is not allowed, use external ID generators:

```java
// UUID (random)
entity.setId(UUID.randomUUID().toString());

// ULID (sortable, timestamp-based)
entity.setId(UlidCreator.getUlid().toString());

// NanoID (URL-safe, compact)
entity.setId(NanoIdUtils.randomNanoId());

// Sequential (using SimpleSequentialRepository)
long id = repository.getNextId();
entity.setId(String.valueOf(id));

// Custom format
entity.setId(String.format("evt_%d_%s",
    System.currentTimeMillis(),
    RandomStringUtils.randomAlphanumeric(8)));
```

## ⚙️ Configuration Options

### Common Builder Options

| Option | Description | Default |
|--------|-------------|---------|
| `connection(host, port, db, user, pass)` | Database connection | Required |
| `tableName(name)` | Table name | Required |
| `retentionDays(days)` | Days to retain data | 30 |
| `maxPoolSize(size)` | Connection pool size | 10 |
| `autoMaintenance(enabled)` | Auto partition management | true |
| `maintenanceTime(time)` | When to run maintenance | 4 AM |

### SimpleSequentialRepository Options

| Option | Description | Default |
|--------|-------------|---------|
| `maxId(value)` | Maximum ID value | Long.MAX_VALUE |
| `wrapAround(enabled)` | Wrap to 1 at max | false |
| `allowClientIds(enabled)` | Accept client IDs | false |
| `stateTableName(name)` | State persistence table | {table}_id_state |

## 🧪 Testing

```bash
# Run all tests
mvn test

# Specific test examples
mvn test -Dtest=SimpleSequentialRepositoryTest
mvn test -Dtest=ChronicleSimulatorOptimizedTest
mvn test -Dtest=SimpleBatchRetrievalTest
```

## ⚠️ Important Notes

1. **String IDs Only**: All entities must use String IDs
2. **External ID Generation**: No AUTO_INCREMENT support
3. **LocalDateTime Sharding**: Sharding key must be LocalDateTime
4. **Thread Safety**: All operations are thread-safe
5. **Graceful Shutdown**: Always call `shutdown()` for proper cleanup
6. **MySQL 5.7+**: Requires MySQL 5.7 or higher

## 🚨 Troubleshooting

### "Maximum ID reached" (SimpleSequentialRepository)
Enable wraparound or increase maxId:
```java
.maxId(Long.MAX_VALUE)
.wrapAround(true)
```

### "Client IDs not allowed"
Enable in builder:
```java
.allowClientIds(true)
```

### State not persisting
Ensure shutdown is called:
```java
Runtime.getRuntime().addShutdownHook(new Thread(repository::shutdown));
```

### Duplicate key errors
Check entity has `@Id(autoGenerated = false)`

## 📈 Production Best Practices

1. **Choose Appropriate Repository Type**:
   - Partitioned: Standard time-series data
   - Multi-Table: Need complete isolation
   - Sequential: High-performance sequential access

2. **Set Realistic Retention**:
   - Balance between storage and query performance
   - Use shorter retention for high-volume data

3. **Monitor Performance**:
   - Track partition operations
   - Monitor connection pool usage
   - Watch ID usage for sequential repositories

4. **Plan for Scale**:
   - Start with single shard/table
   - Add shards as data grows
   - Use range reservation for distributed systems

## 📄 License

This project is proprietary software. All rights reserved.

## 🆘 Support

For issues or questions:
- Review this documentation
- Check test cases for examples
- Open an issue on GitHub

---

**Split-Verse**: Built for scale, designed for simplicity, enforced for correctness.